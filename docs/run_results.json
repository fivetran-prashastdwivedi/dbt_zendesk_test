{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v5.json", "dbt_version": "1.7.1", "generated_at": "2023-11-15T02:15:48.454871Z", "invocation_id": "14f2038d-4595-4d6f-86a7-040121dd8e9e", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:17.730633Z", "completed_at": "2023-11-15T02:15:19.744219Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:19.745164Z", "completed_at": "2023-11-15T02:15:19.745173Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 2.2040460109710693, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__domain_name_tmp", "compiled": true, "compiled_code": "--To disable this model, set the using_domain_names variable within your dbt_project.yml file to False.\n\n\nselect \"index\",\n  \"organization_id\",\n  \"_fivetran_synced\",\n  \"domain_name\" \nfrom \"postgres\".\"zendesk_integration_tests_2\".\"domain_name_data\" as domainname", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__domain_name_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:17.725239Z", "completed_at": "2023-11-15T02:15:19.745434Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:19.746965Z", "completed_at": "2023-11-15T02:15:19.746970Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 2.20563006401062, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__daylight_time_tmp", "compiled": true, "compiled_code": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nselect \"time_zone\",\n  \"year\",\n  \"_fivetran_synced\",\n  \"daylight_end_utc\",\n  \"daylight_offset\",\n  \"daylight_start_utc\"\nfrom \"postgres\".\"zendesk_integration_tests_2\".\"daylight_time_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__daylight_time_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:17.702364Z", "completed_at": "2023-11-15T02:15:19.744844Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:19.746536Z", "completed_at": "2023-11-15T02:15:19.746543Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 2.2069931030273438, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__brand_tmp", "compiled": true, "compiled_code": "select \"id\",\n  \"_fivetran_deleted\",\n  \"_fivetran_synced\",\n  \"active\",\n  \"brand_url\",\n  \"default\",\n  \"has_help_center\",\n  \"help_center_state\",\n  \"logo_content_type\",\n  \"logo_content_url\",\n  \"logo_deleted\",\n  \"logo_file_name\",\n  \"logo_height\",\n  \"logo_id\",\n  \"logo_inline\",\n  \"logo_mapped_content_url\",\n  \"logo_size\",\n  \"logo_url\",\n  \"logo_width\",\n  \"name\",\n  \"subdomain\",\n  \"url\"  \nfrom \"postgres\".\"zendesk_integration_tests_2\".\"brand_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__brand_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:19.923032Z", "completed_at": "2023-11-15T02:15:21.929616Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:21.931507Z", "completed_at": "2023-11-15T02:15:21.931525Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 2.193943977355957, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__organization_tmp", "compiled": true, "compiled_code": "select \"id\",\n  \"_fivetran_synced\",\n  \"created_at\",\n  \"details\",\n  \"external_id\",\n  \"group_id\",\n  \"name\",\n  \"notes\",\n  \"shared_comments\",\n  \"shared_tickets\",\n  \"updated_at\",\n  \"url\"\nfrom \"postgres\".\"zendesk_integration_tests_2\".\"organization_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__organization_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:19.917102Z", "completed_at": "2023-11-15T02:15:22.131315Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:22.132990Z", "completed_at": "2023-11-15T02:15:22.132997Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 2.383471965789795, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__organization_tag_tmp", "compiled": true, "compiled_code": "--To disable this model, set the using_organization_tags variable within your dbt_project.yml file to False.\n\n\nselect \"organization_id\",\n  \"tag\",\n  \"_fivetran_synced\"  \nfrom \"postgres\".\"zendesk_integration_tests_2\".\"organization_tag_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__organization_tag_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:19.911454Z", "completed_at": "2023-11-15T02:15:22.131657Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:22.133354Z", "completed_at": "2023-11-15T02:15:22.133358Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 2.390748977661133, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__group_tmp", "compiled": true, "compiled_code": "select \"id\",\n  \"_fivetran_deleted\",\n  \"_fivetran_synced\",\n  \"created_at\",\n  \"name\",\n  \"updated_at\",\n  \"url\"  \nfrom \"postgres\".\"zendesk_integration_tests_2\".\"group_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__group_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:20.070080Z", "completed_at": "2023-11-15T02:15:22.314773Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:22.321527Z", "completed_at": "2023-11-15T02:15:22.321538Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 2.4558839797973633, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__schedule_holiday_tmp", "compiled": true, "compiled_code": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nselect \"id\",\n  \"schedule_id\",\n  \"_fivetran_deleted\",\n  \"_fivetran_synced\",\n  \"end_date\",\n  \"name\",\n  \"start_date\"\nfrom \"postgres\".\"zendesk_integration_tests_2\".\"schedule_holiday_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__schedule_holiday_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:22.110486Z", "completed_at": "2023-11-15T02:15:24.441689Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:24.444273Z", "completed_at": "2023-11-15T02:15:24.444300Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 2.546424150466919, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__schedule_tmp", "compiled": true, "compiled_code": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nselect \"end_time\",\n  \"id\",\n  \"start_time\",\n  \"_fivetran_deleted\",\n  \"_fivetran_synced\",\n  \"end_time_utc\",\n  \"name\",\n  \"start_time_utc\",\n  \"time_zone\",\n  \"created_at\"\nfrom \"postgres\".\"zendesk_integration_tests_2\".\"schedule_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__schedule_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:22.300588Z", "completed_at": "2023-11-15T02:15:24.984941Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:24.990449Z", "completed_at": "2023-11-15T02:15:24.990465Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 2.8624138832092285, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__ticket_comment_tmp", "compiled": true, "compiled_code": "select \"id\",\n  \"_fivetran_synced\",\n  \"body\",\n  \"created\",\n  \"facebook_comment\",\n  \"public\",\n  \"ticket_id\",\n  \"tweet\",\n  \"user_id\",\n  \"voice_comment\"\nfrom \"postgres\".\"zendesk_integration_tests_2\".\"ticket_comment_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_comment_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:22.315228Z", "completed_at": "2023-11-15T02:15:24.983536Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:24.987911Z", "completed_at": "2023-11-15T02:15:24.987928Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 2.858064889907837, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__ticket_field_history_tmp", "compiled": true, "compiled_code": "select \"field_name\",\n  \"ticket_id\",\n  \"updated\",\n  \"_fivetran_synced\",\n  \"user_id\",\n  \"value\"\nfrom \"postgres\".\"zendesk_integration_tests_2\".\"ticket_field_history_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_field_history_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:22.531880Z", "completed_at": "2023-11-15T02:15:25.178522Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:25.180432Z", "completed_at": "2023-11-15T02:15:25.180438Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 2.7993509769439697, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__ticket_form_history_tmp", "compiled": true, "compiled_code": "--To disable this model, set the using_ticket_form_history variable within your dbt_project.yml file to False.\n\n\nselect \"id\",\n  \"updated_at\",\n  \"_fivetran_deleted\",\n  \"_fivetran_synced\",\n  \"active\",\n  \"created_at\",\n  \"display_name\",\n  \"end_user_visible\",\n  \"name\"\nfrom \"postgres\".\"zendesk_integration_tests_2\".\"ticket_form_history_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_form_history_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:24.655344Z", "completed_at": "2023-11-15T02:15:27.227913Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.232619Z", "completed_at": "2023-11-15T02:15:27.232641Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 2.7174408435821533, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__ticket_schedule_tmp", "compiled": true, "compiled_code": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\n\n\nselect \"created_at\",\n  \"ticket_id\",\n  \"_fivetran_synced\",\n  \"schedule_id\"\nfrom \"postgres\".\"zendesk_integration_tests_2\".\"ticket_schedule_data\"\n\n", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_schedule_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:25.173378Z", "completed_at": "2023-11-15T02:15:27.448353Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.449773Z", "completed_at": "2023-11-15T02:15:27.449779Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 2.380368947982788, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__ticket_tmp", "compiled": true, "compiled_code": "select \"id\",\n  \"_fivetran_synced\",\n  \"allow_channelback\",\n  \"assignee_id\",\n  \"brand_id\",\n  \"created_at\",\n  \"description\",\n  \"due_at\",\n  \"external_id\",\n  \"forum_topic_id\",\n  \"group_id\",\n  \"has_incidents\",\n  \"is_public\",\n  \"organization_id\",\n  \"priority\",\n  \"problem_id\",\n  \"recipient\",\n  \"requester_id\",\n  \"status\",\n  \"subject\",\n  \"submitter_id\",\n  \"system_client\",\n  \"ticket_form_id\",\n  \"type\",\n  \"updated_at\",\n  \"url\",\n  \"via_channel\",\n  \"via_source_from_id\",\n  \"via_source_from_title\",\n  \"via_source_rel\",\n  \"via_source_to_address\",\n  \"via_source_to_name\",\n  \"merged_ticket_ids\",\n  \"via_source_from_address\",\n  \"followup_ids\",\n  \"via_followup_source_id\"\nfrom \"postgres\".\"zendesk_integration_tests_2\".\"ticket_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:25.160112Z", "completed_at": "2023-11-15T02:15:27.448713Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.450178Z", "completed_at": "2023-11-15T02:15:27.450182Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 2.420896053314209, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__ticket_tag_tmp", "compiled": true, "compiled_code": "select \"tag\",\n  \"ticket_id\",\n  \"_fivetran_synced\"\nfrom \"postgres\".\"zendesk_integration_tests_2\".\"ticket_tag_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_tag_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.581703Z", "completed_at": "2023-11-15T02:15:27.586177Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.586888Z", "completed_at": "2023-11-15T02:15:27.586892Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.00650477409362793, "adapter_response": {}, "message": null, "failures": null, "unique_id": "operation.zendesk.zendesk-on-run-start-0", "compiled": true, "compiled_code": "\n\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.588886Z", "completed_at": "2023-11-15T02:15:27.590310Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.590975Z", "completed_at": "2023-11-15T02:15:27.590982Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0033860206604003906, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.brand_data_postgres", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.593119Z", "completed_at": "2023-11-15T02:15:27.595358Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.596049Z", "completed_at": "2023-11-15T02:15:27.596055Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.004230022430419922, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.daylight_time_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.598077Z", "completed_at": "2023-11-15T02:15:27.600335Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.601514Z", "completed_at": "2023-11-15T02:15:27.601521Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.004913806915283203, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.domain_name_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.604100Z", "completed_at": "2023-11-15T02:15:27.605763Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.606393Z", "completed_at": "2023-11-15T02:15:27.606398Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.003730297088623047, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.group_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.608697Z", "completed_at": "2023-11-15T02:15:27.610188Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.610794Z", "completed_at": "2023-11-15T02:15:27.610797Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0035037994384765625, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.organization_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.612717Z", "completed_at": "2023-11-15T02:15:27.614148Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.614784Z", "completed_at": "2023-11-15T02:15:27.614790Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0032830238342285156, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.organization_tag_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.616691Z", "completed_at": "2023-11-15T02:15:27.619104Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.619820Z", "completed_at": "2023-11-15T02:15:27.619824Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0044019222259521484, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.schedule_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.621738Z", "completed_at": "2023-11-15T02:15:27.623085Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.623605Z", "completed_at": "2023-11-15T02:15:27.623608Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.002953767776489258, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.schedule_holiday_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.625417Z", "completed_at": "2023-11-15T02:15:27.626779Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.627341Z", "completed_at": "2023-11-15T02:15:27.627344Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.003149271011352539, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.ticket_comment_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.629231Z", "completed_at": "2023-11-15T02:15:27.630549Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.631138Z", "completed_at": "2023-11-15T02:15:27.631142Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0031349658966064453, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.ticket_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.633168Z", "completed_at": "2023-11-15T02:15:27.634484Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.636147Z", "completed_at": "2023-11-15T02:15:27.636152Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.004230022430419922, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.ticket_field_history_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.638115Z", "completed_at": "2023-11-15T02:15:27.639404Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.639988Z", "completed_at": "2023-11-15T02:15:27.639991Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.003153085708618164, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.ticket_form_history_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.641970Z", "completed_at": "2023-11-15T02:15:27.643402Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.643966Z", "completed_at": "2023-11-15T02:15:27.643973Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.003313302993774414, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.ticket_schedule_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.645938Z", "completed_at": "2023-11-15T02:15:27.647304Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.647956Z", "completed_at": "2023-11-15T02:15:27.647959Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0032508373260498047, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.ticket_tag_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.650212Z", "completed_at": "2023-11-15T02:15:27.651603Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.652263Z", "completed_at": "2023-11-15T02:15:27.652268Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.003454923629760742, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.time_zone_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.654272Z", "completed_at": "2023-11-15T02:15:27.656703Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.657391Z", "completed_at": "2023-11-15T02:15:27.657395Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.004438638687133789, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.user_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.659319Z", "completed_at": "2023-11-15T02:15:27.660666Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.661216Z", "completed_at": "2023-11-15T02:15:27.661219Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0030641555786132812, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.zendesk_integration_tests.user_tag_data", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:25.330580Z", "completed_at": "2023-11-15T02:15:27.566117Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:27.566818Z", "completed_at": "2023-11-15T02:15:27.566826Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 2.5116159915924072, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__time_zone_tmp", "compiled": true, "compiled_code": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nselect \"time_zone\",\n  \"_fivetran_synced\",\n  \"standard_offset\" \nfrom \"postgres\".\"zendesk_integration_tests_2\".\"time_zone_data\" as timezone", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__time_zone_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.554792Z", "completed_at": "2023-11-15T02:15:29.432406Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:29.434569Z", "completed_at": "2023-11-15T02:15:29.434590Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 2.0819220542907715, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__user_tmp", "compiled": true, "compiled_code": "select \"id\",\n  \"_fivetran_synced\",\n  \"active\",\n  \"alias\",\n  \"authenticity_token\",\n  \"chat_only\",\n  \"created_at\",\n  \"details\",\n  \"email\",\n  \"external_id\",\n  \"last_login_at\",\n  \"locale\",\n  \"locale_id\",\n  \"moderator\",\n  \"name\",\n  \"notes\",\n  \"only_private_comments\",\n  \"organization_id\",\n  \"phone\",\n  \"remote_photo_url\",\n  \"restricted_agent\",\n  \"role\",\n  \"shared\",\n  \"shared_agent\",\n  \"signature\",\n  \"suspended\",\n  \"ticket_restriction\",\n  \"time_zone\",\n  \"two_factor_auth_enabled\",\n  \"updated_at\",\n  \"url\",\n  \"verified\"   \nfrom \"postgres\".\"zendesk_integration_tests_2\".\"user_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.376648Z", "completed_at": "2023-11-15T02:15:29.436515Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:29.438271Z", "completed_at": "2023-11-15T02:15:29.438281Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 2.292386054992676, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__user_tag_tmp", "compiled": true, "compiled_code": "--To disable this model, set the using_user_tags variable within your dbt_project.yml file to False.\n\n\nselect \"tag\",\n  \"user_id\",\n  \"_fivetran_synced\"  \nfrom \"postgres\".\"zendesk_integration_tests_2\".\"user_tag_data\"", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user_tag_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.843330Z", "completed_at": "2023-11-15T02:15:29.803506Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:29.804864Z", "completed_at": "2023-11-15T02:15:29.804876Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 2.227077007293701, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__brand", "compiled": true, "compiled_code": "with base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__brand_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_deleted\n    \n as \n    \n    _fivetran_deleted\n    \n, \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    active\n    \n as \n    \n    active\n    \n, \n    \n    \n    brand_url\n    \n as \n    \n    brand_url\n    \n, \n    \n    \n    has_help_center\n    \n as \n    \n    has_help_center\n    \n, \n    \n    \n    help_center_state\n    \n as \n    \n    help_center_state\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    logo_content_type\n    \n as \n    \n    logo_content_type\n    \n, \n    \n    \n    logo_content_url\n    \n as \n    \n    logo_content_url\n    \n, \n    \n    \n    logo_deleted\n    \n as \n    \n    logo_deleted\n    \n, \n    \n    \n    logo_file_name\n    \n as \n    \n    logo_file_name\n    \n, \n    \n    \n    logo_height\n    \n as \n    \n    logo_height\n    \n, \n    \n    \n    logo_id\n    \n as \n    \n    logo_id\n    \n, \n    \n    \n    logo_inline\n    \n as \n    \n    logo_inline\n    \n, \n    \n    \n    logo_mapped_content_url\n    \n as \n    \n    logo_mapped_content_url\n    \n, \n    \n    \n    logo_size\n    \n as \n    \n    logo_size\n    \n, \n    \n    \n    logo_url\n    \n as \n    \n    logo_url\n    \n, \n    \n    \n    logo_width\n    \n as \n    \n    logo_width\n    \n, \n    \n    \n    name\n    \n as \n    \n    name\n    \n, \n    \n    \n    subdomain\n    \n as \n    \n    subdomain\n    \n, \n    \n    \n    url\n    \n as \n    \n    url\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as brand_id,\n        brand_url,\n        name,\n        subdomain,\n        active as is_active\n    from fields\n    where not coalesce(_fivetran_deleted, false)\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__brand\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:27.663059Z", "completed_at": "2023-11-15T02:15:29.803861Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:29.805224Z", "completed_at": "2023-11-15T02:15:29.805228Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 2.4163100719451904, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__domain_name", "compiled": true, "compiled_code": "--To disable this model, set the using_domain_names variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__domain_name_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    domain_name\n    \n as \n    \n    domain_name\n    \n, \n    \n    \n    index\n    \n as \n    \n    index\n    \n, \n    \n    \n    organization_id\n    \n as \n    \n    organization_id\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        organization_id,\n        domain_name,\n        index\n    from fields\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__domain_name\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:29.642288Z", "completed_at": "2023-11-15T02:15:31.819523Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:31.820894Z", "completed_at": "2023-11-15T02:15:31.820908Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 2.3643980026245117, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__daylight_time", "compiled": true, "compiled_code": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__daylight_time_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    daylight_end_utc\n    \n as \n    \n    daylight_end_utc\n    \n, \n    \n    \n    daylight_offset\n    \n as \n    \n    daylight_offset\n    \n, \n    \n    \n    daylight_start_utc\n    \n as \n    \n    daylight_start_utc\n    \n, \n    \n    \n    time_zone\n    \n as \n    \n    time_zone\n    \n, \n    \n    \n    year\n    \n as \n    \n    year\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        daylight_end_utc,\n        daylight_offset,\n        daylight_start_utc,\n        time_zone,\n        year,\n        daylight_offset * 60 as daylight_offset_minutes\n        \n    from fields\n)\n\nselect * from final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__daylight_time\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:29.668897Z", "completed_at": "2023-11-15T02:15:31.820549Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:31.821913Z", "completed_at": "2023-11-15T02:15:31.821916Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 2.3390986919403076, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__organization", "compiled": true, "compiled_code": "with base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__organization_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    details\n    \n as \n    \n    details\n    \n, \n    \n    \n    external_id\n    \n as \n    \n    external_id\n    \n, \n    \n    \n    group_id\n    \n as \n    \n    group_id\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    name\n    \n as \n    \n    name\n    \n, \n    \n    \n    notes\n    \n as \n    \n    notes\n    \n, \n    \n    \n    shared_comments\n    \n as \n    \n    shared_comments\n    \n, \n    \n    \n    shared_tickets\n    \n as \n    \n    shared_tickets\n    \n, \n    \n    \n    updated_at\n    \n as \n    \n    updated_at\n    \n, \n    \n    \n    url\n    \n as \n    \n    url\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as organization_id,\n        created_at,\n        updated_at,\n        details,\n        name,\n        external_id\n\n    from fields\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__organization\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:30.092285Z", "completed_at": "2023-11-15T02:15:32.157586Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:32.159762Z", "completed_at": "2023-11-15T02:15:32.159779Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 2.209670066833496, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__group", "compiled": true, "compiled_code": "with base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__group_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_deleted\n    \n as \n    \n    _fivetran_deleted\n    \n, \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    name\n    \n as \n    \n    name\n    \n, \n    \n    \n    updated_at\n    \n as \n    \n    updated_at\n    \n, \n    \n    \n    url\n    \n as \n    \n    url\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as group_id,\n        name\n    from fields\n    \n    where not coalesce(_fivetran_deleted, false)\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__group\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:30.079808Z", "completed_at": "2023-11-15T02:15:32.274231Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:32.275993Z", "completed_at": "2023-11-15T02:15:32.276009Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 2.3955888748168945, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__organization_tag", "compiled": true, "compiled_code": "--To disable this model, set the using_organization_tags variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__organization_tag_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    organization_id\n    \n as \n    \n    organization_id\n    \n, \n    \n    \n    tag\n    \n as \n    \n    tag\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        organization_id,\n        \n        tag\n        \n        as tags\n    from fields\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__organization_tag\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:32.028270Z", "completed_at": "2023-11-15T02:15:33.895906Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:33.896759Z", "completed_at": "2023-11-15T02:15:33.896778Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 1.9884669780731201, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__schedule", "compiled": true, "compiled_code": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__schedule_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_deleted\n    \n as \n    \n    _fivetran_deleted\n    \n, \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    end_time\n    \n as \n    \n    end_time\n    \n, \n    \n    \n    end_time_utc\n    \n as \n    \n    end_time_utc\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    name\n    \n as \n    \n    name\n    \n, \n    \n    \n    start_time\n    \n as \n    \n    start_time\n    \n, \n    \n    \n    start_time_utc\n    \n as \n    \n    start_time_utc\n    \n, \n    \n    \n    time_zone\n    \n as \n    \n    time_zone\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        cast(id as TEXT) as schedule_id, --need to convert from numeric to string for downstream models to work properly\n        end_time,\n        start_time,\n        name as schedule_name,\n        created_at,\n        time_zone\n        \n    from fields\n    where not coalesce(_fivetran_deleted, false)\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__schedule\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:32.012687Z", "completed_at": "2023-11-15T02:15:34.034840Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:34.036095Z", "completed_at": "2023-11-15T02:15:34.036102Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 2.336825132369995, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__schedule_holiday", "compiled": true, "compiled_code": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__schedule_holiday_tmp\"\n),\n\nfields as (\n\n    select\n        \n    \n    \n    _fivetran_deleted\n    \n as \n    \n    _fivetran_deleted\n    \n, \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    end_date\n    \n as \n    \n    end_date\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    name\n    \n as \n    \n    name\n    \n, \n    \n    \n    schedule_id\n    \n as \n    \n    schedule_id\n    \n, \n    \n    \n    start_date\n    \n as \n    \n    start_date\n    \n\n\n\n    from base\n),\n\nfinal as (\n    \n    select\n        _fivetran_deleted,\n        cast(_fivetran_synced as timestamp ) as _fivetran_synced,\n        cast(end_date as timestamp ) as holiday_end_date_at,\n        cast(id as TEXT ) as holiday_id,\n        name as holiday_name,\n        cast(schedule_id as TEXT ) as schedule_id,\n        cast(start_date as timestamp ) as holiday_start_date_at\n    from fields\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__schedule_holiday\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:32.304848Z", "completed_at": "2023-11-15T02:15:34.375360Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:34.376053Z", "completed_at": "2023-11-15T02:15:34.376059Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 2.1968460083007812, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__ticket_comment", "compiled": true, "compiled_code": "with base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_comment_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    body\n    \n as \n    \n    body\n    \n, \n    cast(null as integer) as \n    \n    call_duration\n    \n , \n    cast(null as integer) as \n    \n    call_id\n    \n , \n    \n    \n    created\n    \n as \n    \n    created\n    \n, \n    \n    \n    facebook_comment\n    \n as \n    \n    facebook_comment\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    cast(null as integer) as \n    \n    location\n    \n , \n    \n    \n    public\n    \n as \n    \n    public\n    \n, \n    cast(null as integer) as \n    \n    recording_url\n    \n , \n    cast(null as timestamp) as \n    \n    started_at\n    \n , \n    \n    \n    ticket_id\n    \n as \n    \n    ticket_id\n    \n, \n    cast(null as integer) as \n    \n    transcription_status\n    \n , \n    cast(null as integer) as \n    \n    transcription_text\n    \n , \n    cast(null as integer) as \n    \n    trusted\n    \n , \n    \n    \n    tweet\n    \n as \n    \n    tweet\n    \n, \n    \n    \n    user_id\n    \n as \n    \n    user_id\n    \n, \n    \n    \n    voice_comment\n    \n as \n    \n    voice_comment\n    \n, \n    cast(null as integer) as \n    \n    voice_comment_transcription_visible\n    \n \n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as ticket_comment_id,\n        _fivetran_synced,\n        body,\n        created as created_at,\n        \n        public as is_public,\n        ticket_id,\n        user_id,\n        facebook_comment as is_facebook_comment,\n        tweet as is_tweet,\n        voice_comment as is_voice_comment\n    from fields\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_comment\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:32.475025Z", "completed_at": "2023-11-15T02:15:34.521908Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:34.522688Z", "completed_at": "2023-11-15T02:15:34.522698Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 2.2146618366241455, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__ticket_field_history", "compiled": true, "compiled_code": "with base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_field_history_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    field_name\n    \n as \n    \n    field_name\n    \n, \n    \n    \n    ticket_id\n    \n as \n    \n    ticket_id\n    \n, \n    \n    \n    updated\n    \n as \n    \n    updated\n    \n, \n    \n    \n    user_id\n    \n as \n    \n    user_id\n    \n, \n    \n    \n    value\n    \n as \n    \n    value\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        ticket_id,\n        field_name,\n        updated as valid_starting_at,\n            lead(updated) over (partition by ticket_id, field_name order by updated) as valid_ending_at,\n        \n        value,\n        user_id\n    from fields\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_field_history\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:34.028874Z", "completed_at": "2023-11-15T02:15:36.074983Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:36.076415Z", "completed_at": "2023-11-15T02:15:36.076432Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 2.2389419078826904, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__ticket_form_history", "compiled": true, "compiled_code": "--To disable this model, set the using_ticket_form_history variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_form_history_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_deleted\n    \n as \n    \n    _fivetran_deleted\n    \n, \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    active\n    \n as \n    \n    active\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    display_name\n    \n as \n    \n    display_name\n    \n, \n    \n    \n    end_user_visible\n    \n as \n    \n    end_user_visible\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    name\n    \n as \n    \n    name\n    \n, \n    \n    \n    updated_at\n    \n as \n    \n    updated_at\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as ticket_form_id,\n        created_at,\n            updated_at,\n        \n        display_name,\n        active as is_active,\n        name\n    from fields\n    where not coalesce(_fivetran_deleted, false)\n    \n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_form_history\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:34.349402Z", "completed_at": "2023-11-15T02:15:36.270160Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:36.276559Z", "completed_at": "2023-11-15T02:15:36.276565Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 2.0957720279693604, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__ticket_schedule", "compiled": true, "compiled_code": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_schedule_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    schedule_id\n    \n as \n    \n    schedule_id\n    \n, \n    \n    \n    ticket_id\n    \n as \n    \n    ticket_id\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        ticket_id,\n        created_at,\n        \n        cast(schedule_id as TEXT) as schedule_id --need to convert from numeric to string for downstream models to work properly\n    from fields\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_schedule\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:34.507020Z", "completed_at": "2023-11-15T02:15:36.493603Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:36.494726Z", "completed_at": "2023-11-15T02:15:36.494743Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 2.2911758422851562, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__ticket", "compiled": true, "compiled_code": "with base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    allow_channelback\n    \n as \n    \n    allow_channelback\n    \n, \n    \n    \n    assignee_id\n    \n as \n    \n    assignee_id\n    \n, \n    \n    \n    brand_id\n    \n as \n    \n    brand_id\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    description\n    \n as \n    \n    description\n    \n, \n    \n    \n    due_at\n    \n as \n    \n    due_at\n    \n, \n    \n    \n    external_id\n    \n as \n    \n    external_id\n    \n, \n    \n    \n    forum_topic_id\n    \n as \n    \n    forum_topic_id\n    \n, \n    \n    \n    group_id\n    \n as \n    \n    group_id\n    \n, \n    \n    \n    has_incidents\n    \n as \n    \n    has_incidents\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    is_public\n    \n as \n    \n    is_public\n    \n, \n    \n    \n    merged_ticket_ids\n    \n as \n    \n    merged_ticket_ids\n    \n, \n    \n    \n    organization_id\n    \n as \n    \n    organization_id\n    \n, \n    \n    \n    priority\n    \n as \n    \n    priority\n    \n, \n    \n    \n    problem_id\n    \n as \n    \n    problem_id\n    \n, \n    \n    \n    recipient\n    \n as \n    \n    recipient\n    \n, \n    \n    \n    requester_id\n    \n as \n    \n    requester_id\n    \n, \n    \n    \n    status\n    \n as \n    \n    status\n    \n, \n    \n    \n    subject\n    \n as \n    \n    subject\n    \n, \n    \n    \n    submitter_id\n    \n as \n    \n    submitter_id\n    \n, \n    cast(null as integer) as \n    \n    system_ccs\n    \n , \n    \n    \n    system_client\n    \n as \n    \n    system_client\n    \n, \n    cast(null as TEXT) as \n    \n    system_ip_address\n    \n , \n    cast(null as integer) as \n    \n    system_json_email_identifier\n    \n , \n    cast(null as float) as \n    \n    system_latitude\n    \n , \n    cast(null as TEXT) as \n    \n    system_location\n    \n , \n    cast(null as float) as \n    \n    system_longitude\n    \n , \n    cast(null as integer) as \n    \n    system_machine_generated\n    \n , \n    cast(null as integer) as \n    \n    system_message_id\n    \n , \n    cast(null as integer) as \n    \n    system_raw_email_identifier\n    \n , \n    \n    \n    ticket_form_id\n    \n as \n    \n    ticket_form_id\n    \n, \n    \n    \n    type\n    \n as \n    \n    type\n    \n, \n    \n    \n    updated_at\n    \n as \n    \n    updated_at\n    \n, \n    \n    \n    url\n    \n as \n    \n    url\n    \n, \n    \n    \n    via_channel\n    \n as \n    \n    via_channel\n    \n, \n    \n    \n    via_source_from_address\n    \n as \n    \n    via_source_from_address\n    \n, \n    \n    \n    via_source_from_id\n    \n as \n    \n    via_source_from_id\n    \n, \n    \n    \n    via_source_from_title\n    \n as \n    \n    via_source_from_title\n    \n, \n    \n    \n    via_source_rel\n    \n as \n    \n    via_source_rel\n    \n, \n    \n    \n    via_source_to_address\n    \n as \n    \n    via_source_to_address\n    \n, \n    \n    \n    via_source_to_name\n    \n as \n    \n    via_source_to_name\n    \n\n\n\n\n        --The below script allows for pass through columns.\n        \n        \n    from base\n),\n\nfinal as (\n    \n    select \n        id as ticket_id,\n        _fivetran_synced,\n        assignee_id,\n        brand_id,\n        created_at,\n            updated_at,\n        \n        description,\n        due_at,\n        group_id,\n        external_id,\n        is_public,\n        organization_id,\n        priority,\n        recipient,\n        requester_id,\n        status,\n        subject,\n        problem_id,\n        submitter_id,\n        ticket_form_id,\n        type,\n        url,\n        via_channel as created_channel,\n        via_source_from_id as source_from_id,\n        via_source_from_title as source_from_title,\n        via_source_rel as source_rel,\n        via_source_to_address as source_to_address,\n        via_source_to_name as source_to_name\n\n        --The below script allows for pass through columns.\n        \n\n    from fields\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:34.691831Z", "completed_at": "2023-11-15T02:15:36.831980Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:36.832675Z", "completed_at": "2023-11-15T02:15:36.832683Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 2.2500369548797607, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__ticket_tag", "compiled": true, "compiled_code": "with base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_tag_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    ticket_id\n    \n as \n    \n    ticket_id\n    \n, \n    \n    \n    tag\n    \n as \n    \n    tag\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        ticket_id,\n        \n        tag as tags\n        \n    from fields\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_tag\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:36.943936Z", "completed_at": "2023-11-15T02:15:36.964746Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:36.965445Z", "completed_at": "2023-11-15T02:15:36.965453Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.02384328842163086, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.not_null_stg_zendesk__brand_brand_id.a2419e1741", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect brand_id\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__brand\"\nwhere brand_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:36.967816Z", "completed_at": "2023-11-15T02:15:36.974123Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:36.974820Z", "completed_at": "2023-11-15T02:15:36.974827Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.008477926254272461, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.unique_stg_zendesk__brand_brand_id.fdf8e23c9e", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    brand_id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__brand\"\nwhere brand_id is not null\ngroup by brand_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:36.977642Z", "completed_at": "2023-11-15T02:15:36.981738Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:36.982438Z", "completed_at": "2023-11-15T02:15:36.982445Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.006412029266357422, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.not_null_stg_zendesk__domain_name_organization_id.a2b5ff8fd3", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect organization_id\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__domain_name\"\nwhere organization_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:36.984687Z", "completed_at": "2023-11-15T02:15:36.994003Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:36.994711Z", "completed_at": "2023-11-15T02:15:36.994725Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.011592864990234375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.dbt_utils_unique_combination_of_columns_stg_zendesk__daylight_time_time_zone__year.88227aef3d", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        time_zone, year\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__daylight_time\"\n    group by time_zone, year\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:36.997052Z", "completed_at": "2023-11-15T02:15:37.000635Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:37.001304Z", "completed_at": "2023-11-15T02:15:37.001314Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.005641937255859375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.not_null_stg_zendesk__organization_organization_id.de7b98c06a", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect organization_id\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__organization\"\nwhere organization_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:37.003431Z", "completed_at": "2023-11-15T02:15:37.007515Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:37.008275Z", "completed_at": "2023-11-15T02:15:37.008280Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.006123065948486328, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.unique_stg_zendesk__organization_organization_id.152be1ab31", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    organization_id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__organization\"\nwhere organization_id is not null\ngroup by organization_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:37.010305Z", "completed_at": "2023-11-15T02:15:37.013975Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:37.014615Z", "completed_at": "2023-11-15T02:15:37.014620Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.005741119384765625, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.not_null_stg_zendesk__group_group_id.7659ed83ec", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect group_id\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__group\"\nwhere group_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:37.016716Z", "completed_at": "2023-11-15T02:15:37.021328Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:37.021997Z", "completed_at": "2023-11-15T02:15:37.022002Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.006488800048828125, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.unique_stg_zendesk__group_group_id.f0658dabcd", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    group_id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__group\"\nwhere group_id is not null\ngroup by group_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:37.023973Z", "completed_at": "2023-11-15T02:15:37.031037Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:37.031743Z", "completed_at": "2023-11-15T02:15:37.031749Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.009121894836425781, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__organization_aggregates", "compiled": true, "compiled_code": "with organizations as (\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__organization\"\n\n--If you use organization tags this will be included, if not it will be ignored.\n\n), organization_tags as (\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__organization_tag\"\n\n), tag_aggregates as (\n    select\n        organizations.organization_id,\n        \n    string_agg(organization_tags.tags, ', ')\n\n as organization_tags\n    from organizations\n\n    left join organization_tags\n        using (organization_id)\n\n    group by 1\n\n\n--If you use using_domain_names tags this will be included, if not it will be ignored.\n\n), domain_names as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__domain_name\"\n\n), domain_aggregates as (\n    select\n        organizations.organization_id,\n        \n    string_agg(domain_names.domain_name, ', ')\n\n as domain_names\n    from organizations\n\n    left join domain_names\n        using(organization_id)\n    \n    group by 1\n\n\n\n), final as (\n    select\n        organizations.*\n\n        --If you use organization tags this will be included, if not it will be ignored.\n        \n        ,tag_aggregates.organization_tags\n        \n\n        --If you use using_domain_names tags this will be included, if not it will be ignored.\n        \n        ,domain_aggregates.domain_names\n        \n\n    from organizations\n\n    --If you use using_domain_names tags this will be included, if not it will be ignored.\n    \n    left join domain_aggregates\n        using(organization_id)\n    \n\n    --If you use organization tags this will be included, if not it will be ignored.\n    \n    left join tag_aggregates\n        using(organization_id)\n    \n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__organization_aggregates\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:37.033818Z", "completed_at": "2023-11-15T02:15:37.037563Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:37.038173Z", "completed_at": "2023-11-15T02:15:37.038177Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.005643129348754883, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.not_null_stg_zendesk__schedule_holiday_holiday_id.52eb08f782", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect holiday_id\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__schedule_holiday\"\nwhere holiday_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:37.040428Z", "completed_at": "2023-11-15T02:15:37.043880Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:37.044488Z", "completed_at": "2023-11-15T02:15:37.044492Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.005434751510620117, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.unique_stg_zendesk__schedule_holiday_holiday_id.0341d5635a", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    holiday_id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__schedule_holiday\"\nwhere holiday_id is not null\ngroup by holiday_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:37.046540Z", "completed_at": "2023-11-15T02:15:37.050210Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:37.050728Z", "completed_at": "2023-11-15T02:15:37.050733Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.005378007888793945, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.not_null_stg_zendesk__ticket_comment_ticket_comment_id.b821f4a606", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect ticket_comment_id\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_comment\"\nwhere ticket_comment_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:37.052659Z", "completed_at": "2023-11-15T02:15:37.057245Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:37.057805Z", "completed_at": "2023-11-15T02:15:37.057812Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.006478071212768555, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.unique_stg_zendesk__ticket_comment_ticket_comment_id.ba353330cd", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    ticket_comment_id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_comment\"\nwhere ticket_comment_id is not null\ngroup by ticket_comment_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:37.059850Z", "completed_at": "2023-11-15T02:15:37.063063Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:37.063685Z", "completed_at": "2023-11-15T02:15:37.063690Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.0050160884857177734, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__latest_ticket_form", "compiled": true, "compiled_code": "--To disable this model, set the using_ticket_form_history variable within your dbt_project.yml file to False.\n\n\nwith ticket_form_history as (\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_form_history\"\n),\n\nlatest_ticket_form as (\n    select\n      *,\n      row_number() over(partition by ticket_form_id order by updated_at desc) as latest_form_index\n    from ticket_form_history\n),\n\nfinal as (\n    select \n        ticket_form_id,\n        created_at,\n        updated_at,\n        display_name,\n        is_active,\n        name,\n        latest_form_index\n    from latest_ticket_form\n\n    where latest_form_index = 1\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__latest_ticket_form\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:37.065618Z", "completed_at": "2023-11-15T02:15:37.069190Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:37.069844Z", "completed_at": "2023-11-15T02:15:37.069849Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.005458831787109375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.not_null_stg_zendesk__ticket_form_history_ticket_form_id.1afe781a17", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect ticket_form_id\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_form_history\"\nwhere ticket_form_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:37.072414Z", "completed_at": "2023-11-15T02:15:37.097351Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:37.098101Z", "completed_at": "2023-11-15T02:15:37.098109Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.027393102645874023, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__field_calendar_spine", "compiled": true, "compiled_code": "\n\nwith  __dbt__cte__int_zendesk__calendar_spine as (\n-- depends_on: \"postgres\".\"zendesk_integration_tests_2\".\"ticket_data\"\n\nwith spine as (\n\n    \n    \n    \n\n    \n    \n        \n            \n\n        \n\n    \n\n\n\n\n\n\n\n\nwith rawdata as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n     + \n    \n    p8.generated_number * power(2, 8)\n     + \n    \n    p9.generated_number * power(2, 9)\n     + \n    \n    p10.generated_number * power(2, 10)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n     cross join \n    \n    p as p8\n     cross join \n    \n    p as p9\n     cross join \n    \n    p as p10\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 1378\n    order by generated_number\n\n\n\n),\n\nall_periods as (\n\n    select (\n        \n\n    cast('2020-02-13' as date) + ((interval '1 day') * (row_number() over (order by 1) - 1))\n\n\n    ) as date_day\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_day <= \n\n    current_date + ((interval '1 week') * (1))\n\n\n\n)\n\nselect * from filtered\n\n\n\n), recast as (\n\n    select cast(date_day as date) as date_day\n    from spine\n\n)\n\nselect *\nfrom recast\n), calendar as (\n\n    select *\n    from __dbt__cte__int_zendesk__calendar_spine\n    \n    where date_day >= (select max(date_day) from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__field_calendar_spine\")\n    \n\n), ticket as (\n\n    select \n        *,\n        -- closed tickets cannot be re-opened or updated, and solved tickets are automatically closed after a pre-defined number of days configured in your Zendesk settings\n        cast( date_trunc('day', case when status != 'closed' then \n    current_timestamp::timestamp\n else updated_at end) as date) as open_until\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket\"\n    \n), joined as (\n\n    select \n        calendar.date_day,\n        ticket.ticket_id\n    from calendar\n    inner join ticket\n        on calendar.date_day >= cast(ticket.created_at as date)\n        -- use this variable to extend the ticket's history past its close date (for reporting/data viz purposes :-)\n        and \n\n    ticket.open_until + ((interval '1 month') * (0))\n\n >= calendar.date_day\n\n), surrogate_key as (\n\n    select\n        *,\n        md5(cast(coalesce(cast(date_day as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ticket_id as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as ticket_day_id\n    from joined\n\n)\n\nselect *\nfrom surrogate_key", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__field_calendar_spine\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:36.276984Z", "completed_at": "2023-11-15T02:15:38.504976Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.506435Z", "completed_at": "2023-11-15T02:15:38.506451Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 2.37085223197937, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__time_zone", "compiled": true, "compiled_code": "--To disable this model, set the using_schedules variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__time_zone_tmp\"\n\n),\n\nfields as (\n\n    select\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    standard_offset\n    \n as \n    \n    standard_offset\n    \n, \n    \n    \n    time_zone\n    \n as \n    \n    time_zone\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        standard_offset,\n        time_zone,\n        -- the standard_offset is a string written as [+/-]HH:MM\n        -- let's convert it to an integer value of minutes\n        cast( \n\n  \n    \n\n    split_part(\n        standard_offset,\n        ':',\n        1\n        )\n\n\n  \n\n as integer ) * 60 +\n            (cast( \n\n  \n    \n\n    split_part(\n        standard_offset,\n        ':',\n        2\n        )\n\n\n  \n\n as integer ) *\n                (case when standard_offset like '-%' then -1 else 1 end) ) as standard_offset_minutes\n    \n    from fields\n)\n\nselect * from final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__time_zone\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.651013Z", "completed_at": "2023-11-15T02:15:38.662139Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.682184Z", "completed_at": "2023-11-15T02:15:38.682193Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.034520864486694336, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__updates", "compiled": true, "compiled_code": "with ticket_history as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_field_history\"\n\n), ticket_comment as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_comment\"\n\n), tickets as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket\"\n\n), updates_union as (\n    select \n        ticket_id,\n        field_name,\n        value,\n        null as is_public,\n        user_id,\n        valid_starting_at,\n        valid_ending_at\n    from ticket_history\n\n    union all\n\n    select\n        ticket_id,\n        cast('comment' as TEXT) as field_name,\n        body as value,\n        is_public,\n        user_id,\n        created_at as valid_starting_at,\n        lead(created_at) over (partition by ticket_id order by created_at) as valid_ending_at\n    from ticket_comment\n\n), final as (\n    select\n        updates_union.*,\n        tickets.created_at as ticket_created_date\n    from updates_union\n\n    left join tickets\n        on tickets.ticket_id = updates_union.ticket_id\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__updates\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.685755Z", "completed_at": "2023-11-15T02:15:38.691089Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.691789Z", "completed_at": "2023-11-15T02:15:38.691797Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.007931232452392578, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.not_null_stg_zendesk__ticket_ticket_id.a8229e6981", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect ticket_id\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket\"\nwhere ticket_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.693677Z", "completed_at": "2023-11-15T02:15:38.697433Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.698111Z", "completed_at": "2023-11-15T02:15:38.698117Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.005693912506103516, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.unique_stg_zendesk__ticket_ticket_id.4be7124521", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    ticket_id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket\"\nwhere ticket_id is not null\ngroup by ticket_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.700127Z", "completed_at": "2023-11-15T02:15:38.703434Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.704036Z", "completed_at": "2023-11-15T02:15:38.704041Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.005032777786254883, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__ticket_aggregates", "compiled": true, "compiled_code": "with tickets as (\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket\"\n\n), ticket_tags as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_tag\"\n\n), brands as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__brand\"\n  \n), ticket_tag_aggregate as (\n  select\n    ticket_tags.ticket_id,\n    \n    string_agg(ticket_tags.tags, ', ')\n\n as ticket_tags\n  from ticket_tags\n  group by 1\n\n), final as (\n  select \n    tickets.*,\n    case when lower(tickets.type) = 'incident'\n      then true\n      else false\n        end as is_incident,\n    brands.name as ticket_brand_name,\n    ticket_tag_aggregate.ticket_tags\n  from tickets\n\n  left join ticket_tag_aggregate\n    using(ticket_id)\n\n  left join brands\n    on brands.brand_id = tickets.brand_id\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_aggregates\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.706110Z", "completed_at": "2023-11-15T02:15:38.727476Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.728122Z", "completed_at": "2023-11-15T02:15:38.728137Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.023299694061279297, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__schedule_spine", "compiled": true, "compiled_code": "\n\n/*\n    The purpose of this model is to create a spine of appropriate timezone offsets to use for schedules, as offsets may change due to Daylight Savings.\n    End result will include `valid_from` and `valid_until` columns which we will use downstream to determine which schedule-offset to associate with each ticket (ie standard time vs daylight time)\n*/\n\nwith timezone as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__time_zone\"\n\n), daylight_time as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__daylight_time\"\n\n), schedule as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__schedule\"   \n\n), schedule_holiday as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__schedule_holiday\"   \n\n), timezone_with_dt as (\n\n    select \n        timezone.*,\n        daylight_time.daylight_start_utc,\n        daylight_time.daylight_end_utc,\n        daylight_time.daylight_offset_minutes\n\n    from timezone \n    left join daylight_time \n        on timezone.time_zone = daylight_time.time_zone\n\n), order_timezone_dt as (\n\n    select \n        *,\n        -- will be null for timezones without any daylight savings records (and the first entry)\n        -- we will coalesce the first entry date with .... the X years ago\n        lag(daylight_end_utc, 1) over (partition by time_zone order by daylight_end_utc asc) as last_daylight_end_utc,\n        -- will be null for timezones without any daylight savings records (and the last entry)\n        -- we will coalesce the last entry date with the current date \n        lead(daylight_start_utc, 1) over (partition by time_zone order by daylight_start_utc asc) as next_daylight_start_utc\n\n    from timezone_with_dt\n\n), split_timezones as (\n\n    -- standard schedule (includes timezones without DT)\n    -- starts: when the last Daylight Savings ended\n    -- ends: when the next Daylight Savings starts\n    select \n        time_zone,\n        standard_offset_minutes as offset_minutes,\n\n        -- last_daylight_end_utc is null for the first record of the time_zone's daylight time, or if the TZ doesn't use DT\n        coalesce(last_daylight_end_utc, cast('1970-01-01' as date)) as valid_from,\n\n        -- daylight_start_utc is null for timezones that don't use DT\n        coalesce(daylight_start_utc, cast( \n\n    \n    current_timestamp::timestamp\n + ((interval '1 year') * (1))\n\n as date)) as valid_until\n\n    from order_timezone_dt\n\n    union all \n\n    -- DT schedule (excludes timezones without it)\n    -- starts: when this Daylight Savings started\n    -- ends: when this Daylight Savings ends\n    select \n        time_zone,\n        -- Pacific Time is -8h during standard time and -7h during DT\n        standard_offset_minutes + daylight_offset_minutes as offset_minutes,\n        daylight_start_utc as valid_from,\n        daylight_end_utc as valid_until\n\n    from order_timezone_dt\n    where daylight_offset_minutes is not null\n\n), calculate_schedules as (\n\n    select \n        schedule.schedule_id,\n        schedule.time_zone,\n        schedule.start_time,\n        schedule.end_time,\n        schedule.created_at,\n        schedule.schedule_name,\n        schedule.start_time - coalesce(split_timezones.offset_minutes, 0) as start_time_utc,\n        schedule.end_time - coalesce(split_timezones.offset_minutes, 0) as end_time_utc,\n\n        -- we'll use these to determine which schedule version to associate tickets with\n        cast(split_timezones.valid_from as timestamp) as valid_from,\n        cast(split_timezones.valid_until as timestamp) as valid_until\n\n    from schedule\n    left join split_timezones\n        on split_timezones.time_zone = schedule.time_zone\n\n-- Now we need take holiday's into consideration and perform the following transformations to account for Holidays in existing schedules\n), holiday_start_end_times as (\n\n    select \n        calculate_schedules.*,\n        schedule_holiday.holiday_name,\n        schedule_holiday.holiday_start_date_at,\n        cast(\n\n    schedule_holiday.holiday_end_date_at + ((interval '1 second') * (86400))\n\n as timestamp) as holiday_end_date_at, -- add 24*60*60 seconds\n        cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    schedule_holiday.holiday_start_date_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date) as timestamp) as holiday_week_start,\n        cast(cast(\n\n    -- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    schedule_holiday.holiday_end_date_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date) + ((interval '1 day') * (6))\n\n as date) as timestamp) as holiday_week_end\n    from schedule_holiday\n    inner join calculate_schedules\n        on calculate_schedules.schedule_id = schedule_holiday.schedule_id\n        and schedule_holiday.holiday_start_date_at >= calculate_schedules.valid_from \n        and schedule_holiday.holiday_start_date_at < calculate_schedules.valid_until\n\n-- Let's calculate the start and end date of the Holiday in terms of minutes from Sunday (like other Zendesk schedules)\n), holiday_minutes as(\n\n    select\n        *,\n        \n        (\n        (\n        ((holiday_start_date_at)::date - (holiday_week_start)::date)\n     * 24 + date_part('hour', (holiday_start_date_at)::timestamp) - date_part('hour', (holiday_week_start)::timestamp))\n     * 60 + date_part('minute', (holiday_start_date_at)::timestamp) - date_part('minute', (holiday_week_start)::timestamp))\n     as minutes_from_sunday_start,\n        \n        (\n        (\n        ((holiday_end_date_at)::date - (holiday_week_start)::date)\n     * 24 + date_part('hour', (holiday_end_date_at)::timestamp) - date_part('hour', (holiday_week_start)::timestamp))\n     * 60 + date_part('minute', (holiday_end_date_at)::timestamp) - date_part('minute', (holiday_week_start)::timestamp))\n     as minutes_from_sunday_end\n    from holiday_start_end_times\n\n-- Determine which schedule days include a holiday\n), holiday_check as (\n\n    select\n        *,\n        case when minutes_from_sunday_start < start_time_utc and minutes_from_sunday_end > end_time_utc \n            then holiday_name \n        end as holiday_name_check\n    from holiday_minutes\n\n-- Consolidate the holiday records that were just created\n), holiday_consolidated as (\n\n    select \n        schedule_id, \n        time_zone, \n        schedule_name, \n        valid_from, \n        valid_until, \n        start_time_utc, \n        end_time_utc, \n        holiday_week_start,\n        cast(\n\n    holiday_week_end + ((interval '1 second') * (86400))\n\n as timestamp) as holiday_week_end,\n        max(holiday_name_check) as holiday_name_check\n    from holiday_check\n    group by 1,2,3,4,5,6,7,8,9\n\n-- Since we have holiday schedules and normal schedules, we need to union them into a holistic schedule spine\n), spine_union as (\n\n    select\n        schedule_id, \n        time_zone, \n        schedule_name, \n        valid_from, \n        valid_until, \n        start_time_utc, \n        end_time_utc, \n        holiday_week_start,\n        holiday_week_end,\n        holiday_name_check\n    from holiday_consolidated\n\n    union all\n\n    select\n        schedule_id, \n        time_zone, \n        schedule_name, \n        valid_from, \n        valid_until, \n        start_time_utc, \n        end_time_utc, \n        null as holiday_week_start,\n        null as holiday_week_end,\n        null as holiday_name_check\n    from calculate_schedules\n\n-- Now that we have an understanding of which weeks are holiday's let's consolidate them with non holiday weeks\n), all_periods as (\n\n    select distinct\n        schedule_id,\n        holiday_week_start as period_start,\n        holiday_week_end as period_end,\n        start_time_utc,\n        end_time_utc,\n        holiday_name_check,\n        true as is_holiday_week\n    from spine_union\n    where holiday_week_start is not null\n        and holiday_week_end is not null\n\n    union all\n\n    select distinct\n        schedule_id,\n        valid_from as period_start,\n        valid_until as period_end,\n        start_time_utc,\n        end_time_utc,\n        cast(null as TEXT) as holiday_name_check,\n        false as is_holiday_week\n    from spine_union\n\n-- We have holiday and non holiday schedules together, now let's sort them to understand the previous end and next start of neighboring schedules\n), sorted_periods as (\n\n    select distinct\n        *,\n        lag(period_end) over (partition by schedule_id order by period_start, start_time_utc) as prev_end,\n        lead(period_start) over (partition by schedule_id order by period_start, start_time_utc) as next_start\n    from all_periods\n\n-- We need to adjust some non holiday schedules in order to properly fill holiday gaps in the schedules later down the transformation\n), non_holiday_period_adjustments as (\n\n    select\n        schedule_id, \n        period_start, \n        period_end,\n        prev_end,\n        next_start,\n        -- taking first_value/last_value because prev_end and next_start are inconsistent within the schedule partitions -- they all include a record that is outside the partition. so we need to ignore those erroneous records that slip in\n        coalesce(greatest(case \n            when not is_holiday_week and prev_end is not null then first_value(prev_end) over (partition by schedule_id, period_start order by start_time_utc rows between unbounded preceding and unbounded following)\n            else period_start\n        end, period_start), period_start) as valid_from,\n        coalesce(case \n            when not is_holiday_week and next_start is not null then last_value(next_start) over (partition by schedule_id, period_start order by start_time_utc rows between unbounded preceding and unbounded following)\n            else period_end\n        end, period_end) as valid_until,\n        start_time_utc,\n        end_time_utc,\n        holiday_name_check,\n        is_holiday_week\n    from sorted_periods\n\n-- A few window function results will be leveraged downstream. Let's generate them now.\n), gap_starter as (\n    select \n        *,\n        max(period_end) over (partition by schedule_id) as max_valid_until,\n        last_value(next_start) over (partition by schedule_id, period_start order by valid_until rows between unbounded preceding and unbounded following) as lead_next_start,\n        first_value(prev_end) over (partition by schedule_id, valid_from order by start_time_utc rows between unbounded preceding and unbounded following) as first_prev_end\n    from non_holiday_period_adjustments\n\n-- There may be gaps in holiday and non holiday schedules, so we need to identify where these gaps are\n), gap_adjustments as(\n\n    select \n        *,\n        -- In order to identify the gaps we check to see if the valid_from and previous valid_until are right next to one. If we add two hours to the previous valid_until it should always be greater than the current valid_from.\n        -- However, if the valid_from is greater instead then we can identify that this period has a gap that needs to be filled.\n        case \n        when cast(\n\n    valid_until + ((interval '1 hour') * (2))\n\n as timestamp) < cast(lead_next_start as timestamp)\n            then 'gap'\n        when (lead_next_start is null and valid_from < max_valid_until and period_end != max_valid_until)\n            then 'gap'\n            else null\n        end as is_schedule_gap\n\n    from gap_starter\n\n-- We know where the gaps are, so now lets prime the data to fill those gaps\n), schedule_spine_primer as (\n\n    select \n        schedule_id, \n        valid_from,\n        valid_until,\n        start_time_utc,\n        end_time_utc,\n        lead_next_start,\n        max_valid_until,\n        holiday_name_check,\n        is_holiday_week,\n        max(is_schedule_gap) over (partition by schedule_id, valid_until) as is_gap_period,\n        lead(valid_from) over (partition by schedule_id order by valid_from, start_time_utc) as fill_primer\n    from gap_adjustments\n\n-- We know the gaps and where they are, so let's fill them with the following union\n), final_union as (\n\n    -- For all gap periods, let's properly create a schedule filled before the holiday.\n    select \n        schedule_id,\n        valid_until as valid_from,\n        coalesce(last_value(fill_primer) over (partition by schedule_id, valid_until order by start_time_utc rows between unbounded preceding and unbounded following), max_valid_until) as valid_until,\n        start_time_utc, \n        end_time_utc, \n        cast(null as TEXT) as holiday_name_check,\n        false as is_holiday_week\n    from schedule_spine_primer\n    where is_gap_period is not null\n\n    union all\n\n    -- Fill all other normal schedules.\n    select\n        schedule_id, \n        valid_from,\n        valid_until,\n        start_time_utc,\n        end_time_utc,\n        holiday_name_check,\n        is_holiday_week\n    from schedule_spine_primer\n\n-- We can finally filter out the holiday_name_check results as the gap filling properly filled in the gaps for holidays\n), final as(\n\n    select\n        schedule_id, \n        valid_from,\n        valid_until,\n        start_time_utc,\n        end_time_utc,\n        is_holiday_week\n    from final_union\n    where holiday_name_check is null\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__schedule_spine\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.730418Z", "completed_at": "2023-11-15T02:15:38.735481Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.736057Z", "completed_at": "2023-11-15T02:15:38.736062Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.006904125213623047, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.not_null_stg_zendesk__time_zone_time_zone.b25b3452b1", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect time_zone\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__time_zone\"\nwhere time_zone is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.738183Z", "completed_at": "2023-11-15T02:15:38.741838Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.742456Z", "completed_at": "2023-11-15T02:15:38.742464Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.005637168884277344, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.unique_stg_zendesk__time_zone_time_zone.67995adbaf", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    time_zone as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__time_zone\"\nwhere time_zone is not null\ngroup by time_zone\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.744515Z", "completed_at": "2023-11-15T02:15:38.747256Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.747791Z", "completed_at": "2023-11-15T02:15:38.747796Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.004499912261962891, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__assignee_updates", "compiled": true, "compiled_code": "with ticket_updates as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__updates\"\n\n), ticket as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket\"\n\n), ticket_requester as (\n    select\n        ticket.ticket_id,\n        ticket.assignee_id,\n        ticket_updates.valid_starting_at\n\n    from ticket\n\n    left join ticket_updates\n        on ticket_updates.ticket_id = ticket.ticket_id\n            and ticket_updates.user_id = ticket.assignee_id\n\n), final as (\n    select \n        ticket_id,\n        assignee_id,\n        max(valid_starting_at) as last_updated,\n        count(*) as total_updates\n    from ticket_requester\n\n    group by 1, 2\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__assignee_updates\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.749708Z", "completed_at": "2023-11-15T02:15:38.752628Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.753317Z", "completed_at": "2023-11-15T02:15:38.753327Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.005007028579711914, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__requester_updates", "compiled": true, "compiled_code": "with ticket_updates as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__updates\"\n\n), ticket as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket\"\n\n), ticket_requester as (\n    select\n        ticket.ticket_id,\n        ticket.requester_id,\n        ticket_updates.valid_starting_at\n\n    from ticket\n\n    left join ticket_updates\n        on ticket_updates.ticket_id = ticket.ticket_id\n            and ticket_updates.user_id = ticket.requester_id\n\n), final as (\n    select \n        ticket_id,\n        requester_id,\n        max(valid_starting_at) as last_updated,\n        count(*) as total_updates\n    from ticket_requester\n\n    group by 1, 2\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__requester_updates\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.755663Z", "completed_at": "2023-11-15T02:15:38.759660Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.760275Z", "completed_at": "2023-11-15T02:15:38.760281Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.005883932113647461, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__ticket_historical_assignee", "compiled": true, "compiled_code": "with assignee_updates as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__updates\"\n    where field_name = 'assignee_id'\n\n), calculate_metrics as (\n    select\n        ticket_id,\n        field_name as assignee_id,\n        value,\n        ticket_created_date,\n        valid_starting_at,\n        lag(valid_starting_at) over (partition by ticket_id order by valid_starting_at) as previous_update,\n        lag(value) over (partition by ticket_id order by valid_starting_at) as previous_assignee,\n        first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at, ticket_id rows unbounded preceding) as first_agent_assignment_date,\n        first_value(value) over (partition by ticket_id order by valid_starting_at, ticket_id rows unbounded preceding) as first_assignee_id,\n        first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_agent_assignment_date,\n        first_value(value) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_assignee_id,\n        count(value) over (partition by ticket_id) as assignee_stations_count\n    from assignee_updates\n\n), unassigned_time as (\n    select\n        ticket_id,\n        sum(case when assignee_id is not null and previous_assignee is null \n            then \n        (\n        (\n        (\n        ((valid_starting_at)::date - (coalesce(previous_update, ticket_created_date))::date)\n     * 24 + date_part('hour', (valid_starting_at)::timestamp) - date_part('hour', (coalesce(previous_update, ticket_created_date))::timestamp))\n     * 60 + date_part('minute', (valid_starting_at)::timestamp) - date_part('minute', (coalesce(previous_update, ticket_created_date))::timestamp))\n     * 60 + floor(date_part('second', (valid_starting_at)::timestamp)) - floor(date_part('second', (coalesce(previous_update, ticket_created_date))::timestamp)))\n     / 60\n            else 0\n                end) as ticket_unassigned_duration_calendar_minutes,\n        count(distinct value) as unique_assignee_count\n    from calculate_metrics\n\n    group by 1\n\n), window_group as (\n    select\n        calculate_metrics.ticket_id,\n        calculate_metrics.first_agent_assignment_date,\n        calculate_metrics.first_assignee_id,\n        calculate_metrics.last_agent_assignment_date,\n        calculate_metrics.last_assignee_id,\n        calculate_metrics.assignee_stations_count\n    from calculate_metrics\n\n    group by 1,2,3,4,5,6\n\n), final as (\n    select\n        window_group.*,\n        unassigned_time.unique_assignee_count,\n        unassigned_time.ticket_unassigned_duration_calendar_minutes\n    from window_group\n\n    left join unassigned_time\n        using(ticket_id)\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_historical_assignee\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.762237Z", "completed_at": "2023-11-15T02:15:38.766075Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.766739Z", "completed_at": "2023-11-15T02:15:38.766745Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.0057027339935302734, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__ticket_historical_group", "compiled": true, "compiled_code": "with ticket_group_history as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__updates\"\n    where field_name = 'group_id'\n\n), group_breakdown as (\n    select\n  \n        ticket_id,\n        valid_starting_at,\n        valid_ending_at,\n        value as group_id\n    from ticket_group_history\n\n), final as (\n    select\n        ticket_id,\n        count(group_id) as group_stations_count\n    from group_breakdown\n\n    group by 1\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_historical_group\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.768671Z", "completed_at": "2023-11-15T02:15:38.771455Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.772135Z", "completed_at": "2023-11-15T02:15:38.772140Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.0046198368072509766, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__ticket_historical_satisfaction", "compiled": true, "compiled_code": "with satisfaction_updates as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__updates\"\n    where field_name in ('satisfaction_score', 'satisfaction_comment', 'satisfaction_reason_code') \n\n), latest_reason as (\n    select\n        ticket_id,\n        first_value(value) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as latest_satisfaction_reason\n    from satisfaction_updates\n\n    where field_name = 'satisfaction_reason_code'\n\n), latest_comment as (\n    select\n        ticket_id,\n        first_value(value) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as latest_satisfaction_comment\n    from satisfaction_updates\n\n    where field_name = 'satisfaction_comment'\n\n), first_and_latest_score as (\n    select\n        ticket_id,\n        first_value(value) over (partition by ticket_id order by valid_starting_at, ticket_id rows unbounded preceding) as first_satisfaction_score,\n        first_value(value) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as latest_satisfaction_score\n    from satisfaction_updates\n\n    where field_name = 'satisfaction_score' and value != 'offered'\n\n), satisfaction_scores as (\n    select\n        ticket_id,\n        count(value) over (partition by ticket_id) as count_satisfaction_scores,\n        case when lag(value) over (partition by ticket_id order by valid_starting_at desc) = 'good' and value = 'bad'\n            then 1\n            else 0\n                end as good_to_bad_score,\n        case when lag(value) over (partition by ticket_id order by valid_starting_at desc) = 'bad' and value = 'good'\n            then 1\n            else 0\n                end as bad_to_good_score\n    from satisfaction_updates\n    where field_name = 'satisfaction_score'\n\n), score_group as (\n    select\n        ticket_id,\n        count_satisfaction_scores,\n        sum(good_to_bad_score) as total_good_to_bad_score,\n        sum(bad_to_good_score) as total_bad_to_good_score\n    from satisfaction_scores\n\n    group by 1, 2\n\n), window_group as (\n    select\n        satisfaction_updates.ticket_id,\n        latest_reason.latest_satisfaction_reason,\n        latest_comment.latest_satisfaction_comment,\n        first_and_latest_score.first_satisfaction_score,\n        first_and_latest_score.latest_satisfaction_score,\n        score_group.count_satisfaction_scores,\n        score_group.total_good_to_bad_score,\n        score_group.total_bad_to_good_score\n\n    from satisfaction_updates\n\n    left join latest_reason\n        on satisfaction_updates.ticket_id = latest_reason.ticket_id\n\n    left join latest_comment\n        on satisfaction_updates.ticket_id = latest_comment.ticket_id\n\n    left join first_and_latest_score\n        on satisfaction_updates.ticket_id = first_and_latest_score.ticket_id\n\n    left join score_group\n        on satisfaction_updates.ticket_id = score_group.ticket_id\n\n    group by 1, 2, 3, 4, 5, 6, 7, 8\n\n), final as (\n    select\n        ticket_id,\n        latest_satisfaction_reason,\n        latest_satisfaction_comment,\n        first_satisfaction_score,\n        latest_satisfaction_score,\n        case when count_satisfaction_scores > 0\n            then (count_satisfaction_scores - 1) --Subtracting one as the first score is always \"offered\".\n            else count_satisfaction_scores\n                end as count_satisfaction_scores,\n        case when total_good_to_bad_score > 0\n            then true\n            else false\n                end as is_good_to_bad_satisfaction_score,\n        case when total_bad_to_good_score > 0\n            then true\n            else false\n                end as is_bad_to_good_satisfaction_score\n    from window_group\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_historical_satisfaction\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.773966Z", "completed_at": "2023-11-15T02:15:38.777903Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.778522Z", "completed_at": "2023-11-15T02:15:38.778529Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.0058040618896484375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__ticket_historical_status", "compiled": true, "compiled_code": "-- To do -- can we delete ticket_status_counter and unique_status_counter?\n\nwith ticket_status_history as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__updates\"\n    where field_name = 'status'\n\n)\n\n  select\n  \n    ticket_id,\n    valid_starting_at,\n    valid_ending_at,\n    \n        (\n        (\n        ((coalesce(valid_ending_at, \n    current_timestamp::timestamp\n))::date - (valid_starting_at)::date)\n     * 24 + date_part('hour', (coalesce(valid_ending_at, \n    current_timestamp::timestamp\n))::timestamp) - date_part('hour', (valid_starting_at)::timestamp))\n     * 60 + date_part('minute', (coalesce(valid_ending_at, \n    current_timestamp::timestamp\n))::timestamp) - date_part('minute', (valid_starting_at)::timestamp))\n     as status_duration_calendar_minutes,\n    value as status,\n    -- MIGHT BE ABLE TO DELETE ROWS BELOW\n    row_number() over (partition by ticket_id order by valid_starting_at) as ticket_status_counter,\n    row_number() over (partition by ticket_id, value order by valid_starting_at) as unique_status_counter\n\n  from ticket_status_history", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_historical_status\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.780699Z", "completed_at": "2023-11-15T02:15:38.787116Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.787810Z", "completed_at": "2023-11-15T02:15:38.787818Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.00837397575378418, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__sla_policy_applied", "compiled": true, "compiled_code": "-- step 1, figure out when sla was applied to tickets\n\n-- more on SLA policies here: https://support.zendesk.com/hc/en-us/articles/204770038-Defining-and-using-SLA-policies-Professional-and-Enterprise-\n-- SLA policies are calculated for next_reply_time, first_reply_time, agent_work_time, requester_wait_time.  If you're company uses other SLA metrics, and would like this\n-- package to support those, please reach out to the Fivetran team on Slack.\n\nwith ticket_field_history as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__updates\"\n\n), sla_policy_name as (\n\n  select \n    *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__updates\"\n  where field_name = ('sla_policy')\n\n), ticket as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_aggregates\"\n\n), sla_policy_applied as (\n\n  select\n    ticket_field_history.ticket_id,\n    ticket.created_at as ticket_created_at,\n    ticket_field_history.valid_starting_at,\n    ticket.status as ticket_current_status,\n    ticket_field_history.field_name as metric,\n    case when ticket_field_history.field_name = 'first_reply_time' then row_number() over (partition by ticket_field_history.ticket_id, ticket_field_history.field_name order by ticket_field_history.valid_starting_at desc) else 1 end as latest_sla,\n    case when ticket_field_history.field_name = 'first_reply_time' then ticket.created_at else ticket_field_history.valid_starting_at end as sla_applied_at,\n    cast(\n\n  ticket_field_history.value::json #>> '{minutes}'\n\n as integer ) as target,\n    \n\n  ticket_field_history.value::json #>> '{in_business_hours}'\n\n = 'true' as in_business_hours\n  from ticket_field_history\n  join ticket\n    on ticket.ticket_id = ticket_field_history.ticket_id\n  where ticket_field_history.value is not null\n    and ticket_field_history.field_name in ('next_reply_time', 'first_reply_time', 'agent_work_time', 'requester_wait_time')\n\n), final as (\n  select\n    sla_policy_applied.*,\n    sla_policy_name.value as sla_policy_name\n  from sla_policy_applied\n  left join sla_policy_name\n    on sla_policy_name.ticket_id = sla_policy_applied.ticket_id\n      and sla_policy_applied.valid_starting_at >= sla_policy_name.valid_starting_at\n      and sla_policy_applied.valid_starting_at < coalesce(sla_policy_name.valid_ending_at, \n    current_timestamp::timestamp\n) \n  where sla_policy_applied.latest_sla = 1\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__sla_policy_applied\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.805780Z", "completed_at": "2023-11-15T02:15:38.809970Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.810480Z", "completed_at": "2023-11-15T02:15:38.810486Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.005939006805419922, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__agent_work_time_filtered_statuses", "compiled": true, "compiled_code": "with agent_work_time_sla as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__sla_policy_applied\"\n  where metric = 'agent_work_time'\n\n), ticket_historical_status as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_historical_status\"\n    \n--This captures the statuses of the ticket while the agent work time sla was active for the ticket.\n), agent_work_time_filtered_statuses as (\n\n  select  \n    ticket_historical_status.ticket_id,\n    greatest(ticket_historical_status.valid_starting_at, agent_work_time_sla.sla_applied_at) as valid_starting_at,\n    coalesce(\n      ticket_historical_status.valid_ending_at, \n      \n\n    \n    current_timestamp::timestamp\n + ((interval '1 day') * (30))\n\n ) as valid_ending_at, --assumes current status continues into the future. This is necessary to predict future SLA breaches (not just past).\n    ticket_historical_status.status as ticket_status,\n    agent_work_time_sla.sla_applied_at,\n    agent_work_time_sla.target,    \n    agent_work_time_sla.sla_policy_name,\n    agent_work_time_sla.ticket_created_at,\n    agent_work_time_sla.in_business_hours\n  from ticket_historical_status\n  join agent_work_time_sla\n    on ticket_historical_status.ticket_id = agent_work_time_sla.ticket_id\n  where ticket_historical_status.status in ('new', 'open') -- these are the only statuses that count as \"agent work time\"\n  and sla_applied_at < valid_ending_at\n\n)\nselect *\nfrom agent_work_time_filtered_statuses", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__agent_work_time_filtered_statuses\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.812577Z", "completed_at": "2023-11-15T02:15:38.815729Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.816484Z", "completed_at": "2023-11-15T02:15:38.816490Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.005159139633178711, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__reply_time_calendar_hours", "compiled": true, "compiled_code": "--REPLY TIME SLA\n-- step 2, figure out when the sla will breach for sla's in calendar hours. The calculation is relatively straightforward.\n\nwith sla_policy_applied as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__sla_policy_applied\"\n\n), final as (\n  select\n    *,\n    \n\n    sla_applied_at + ((interval '1 minute') * (cast(target as integer )))\n\n as sla_breach_at\n  from sla_policy_applied\n  where not in_business_hours\n    and metric in ('next_reply_time', 'first_reply_time')\n\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__reply_time_calendar_hours\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.818356Z", "completed_at": "2023-11-15T02:15:38.821270Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.821740Z", "completed_at": "2023-11-15T02:15:38.821745Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.004747867584228516, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__requester_wait_time_filtered_statuses", "compiled": true, "compiled_code": "with requester_wait_time_sla as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__sla_policy_applied\"\n  where metric = 'requester_wait_time'\n\n), ticket_historical_status as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_historical_status\"\n    \n--This captures the statuses of the ticket while the requester wait time sla was active for the ticket.\n), requester_wait_time_filtered_statuses as (\n\n  select  \n    ticket_historical_status.ticket_id,\n    greatest(ticket_historical_status.valid_starting_at, requester_wait_time_sla.sla_applied_at) as valid_starting_at,\n    coalesce(\n      ticket_historical_status.valid_ending_at, \n      \n\n    \n    current_timestamp::timestamp\n + ((interval '1 day') * (30))\n\n ) as valid_ending_at, --assumes current status continues into the future. This is necessary to predict future SLA breaches (not just past).\n    ticket_historical_status.status as ticket_status,\n    requester_wait_time_sla.sla_applied_at,\n    requester_wait_time_sla.target,\n    requester_wait_time_sla.sla_policy_name,\n    requester_wait_time_sla.ticket_created_at,\n    requester_wait_time_sla.in_business_hours\n  from ticket_historical_status\n  join requester_wait_time_sla\n    on ticket_historical_status.ticket_id = requester_wait_time_sla.ticket_id\n  where ticket_historical_status.status in ('new', 'open', 'on-hold', 'hold') -- these are the only statuses that count as \"requester wait time\"\n  and sla_applied_at < valid_ending_at\n\n)\nselect *\nfrom requester_wait_time_filtered_statuses", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__requester_wait_time_filtered_statuses\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.824866Z", "completed_at": "2023-11-15T02:15:38.827923Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.828432Z", "completed_at": "2023-11-15T02:15:38.828437Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.005667686462402344, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__agent_work_time_calendar_hours", "compiled": true, "compiled_code": "-- Calculate breach time for agent work time, calendar hours\nwith agent_work_time_filtered_statuses as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__agent_work_time_filtered_statuses\"\n  where not in_business_hours\n\n), agent_work_time_calendar_minutes as (\n\n  select \n    *,\n    \n        (\n        (\n        ((valid_ending_at)::date - (valid_starting_at)::date)\n     * 24 + date_part('hour', (valid_ending_at)::timestamp) - date_part('hour', (valid_starting_at)::timestamp))\n     * 60 + date_part('minute', (valid_ending_at)::timestamp) - date_part('minute', (valid_starting_at)::timestamp))\n     as calendar_minutes,\n    sum(\n        (\n        (\n        ((valid_ending_at)::date - (valid_starting_at)::date)\n     * 24 + date_part('hour', (valid_ending_at)::timestamp) - date_part('hour', (valid_starting_at)::timestamp))\n     * 60 + date_part('minute', (valid_ending_at)::timestamp) - date_part('minute', (valid_starting_at)::timestamp))\n     ) \n      over (partition by ticket_id, sla_applied_at order by valid_starting_at rows between unbounded preceding and current row) as running_total_calendar_minutes\n  from agent_work_time_filtered_statuses\n\n), agent_work_time_calendar_minutes_flagged as (\n\nselect \n  agent_work_time_calendar_minutes.*,\n  target - running_total_calendar_minutes as remaining_target_minutes,\n  case when (target - running_total_calendar_minutes) < 0 \n      and \n        (lag(target - running_total_calendar_minutes) over\n        (partition by ticket_id, sla_applied_at order by valid_starting_at) >= 0 \n        or \n        lag(target - running_total_calendar_minutes) over\n        (partition by ticket_id, sla_applied_at order by valid_starting_at) is null) \n        then true else false end as is_breached_during_schedule\n        \nfrom  agent_work_time_calendar_minutes\n\n), final as (\n  select\n    *,\n    (remaining_target_minutes + calendar_minutes) as breach_minutes,\n    \n\n    valid_starting_at + ((interval '1 minute') * ((remaining_target_minutes + calendar_minutes)))\n\n as sla_breach_at\n  from agent_work_time_calendar_minutes_flagged\n\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__agent_work_time_calendar_hours\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.830252Z", "completed_at": "2023-11-15T02:15:38.834182Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.834673Z", "completed_at": "2023-11-15T02:15:38.834679Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.00562286376953125, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__requester_wait_time_calendar_hours", "compiled": true, "compiled_code": "-- Calculate breach time for requester wait time, calendar hours\nwith requester_wait_time_filtered_statuses as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__requester_wait_time_filtered_statuses\"\n  where not in_business_hours\n\n), requester_wait_time_calendar_minutes as (\n\n  select \n    *,\n    \n        (\n        (\n        ((valid_ending_at)::date - (valid_starting_at)::date)\n     * 24 + date_part('hour', (valid_ending_at)::timestamp) - date_part('hour', (valid_starting_at)::timestamp))\n     * 60 + date_part('minute', (valid_ending_at)::timestamp) - date_part('minute', (valid_starting_at)::timestamp))\n     as calendar_minutes,\n    sum(\n        (\n        (\n        ((valid_ending_at)::date - (valid_starting_at)::date)\n     * 24 + date_part('hour', (valid_ending_at)::timestamp) - date_part('hour', (valid_starting_at)::timestamp))\n     * 60 + date_part('minute', (valid_ending_at)::timestamp) - date_part('minute', (valid_starting_at)::timestamp))\n     ) \n      over (partition by ticket_id, sla_applied_at order by valid_starting_at rows between unbounded preceding and current row) as running_total_calendar_minutes\n  from requester_wait_time_filtered_statuses\n\n), requester_wait_time_calendar_minutes_flagged as (\n\nselect \n  requester_wait_time_calendar_minutes.*,\n  target - running_total_calendar_minutes as remaining_target_minutes,\n  case when (target - running_total_calendar_minutes) < 0 \n      and \n        (lag(target - running_total_calendar_minutes) over\n        (partition by ticket_id, sla_applied_at order by valid_starting_at) >= 0 \n        or \n        lag(target - running_total_calendar_minutes) over\n        (partition by ticket_id, sla_applied_at order by valid_starting_at) is null) \n        then true else false end as is_breached_during_schedule\n        \nfrom  requester_wait_time_calendar_minutes\n\n), final as (\n  select\n    *,\n    (remaining_target_minutes + calendar_minutes) as breach_minutes,\n    \n\n    valid_starting_at + ((interval '1 minute') * ((remaining_target_minutes + calendar_minutes)))\n\n as sla_breach_at\n  from requester_wait_time_calendar_minutes_flagged\n\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__requester_wait_time_calendar_hours\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:36.487384Z", "completed_at": "2023-11-15T02:15:38.683958Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.685400Z", "completed_at": "2023-11-15T02:15:38.685410Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 2.38765811920166, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__user", "compiled": true, "compiled_code": "with base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    active\n    \n as \n    \n    active\n    \n, \n    \n    \n    alias\n    \n as \n    \n    alias\n    \n, \n    \n    \n    authenticity_token\n    \n as \n    \n    authenticity_token\n    \n, \n    \n    \n    chat_only\n    \n as \n    \n    chat_only\n    \n, \n    \n    \n    created_at\n    \n as \n    \n    created_at\n    \n, \n    \n    \n    details\n    \n as \n    \n    details\n    \n, \n    \n    \n    email\n    \n as \n    \n    email\n    \n, \n    \n    \n    external_id\n    \n as \n    \n    external_id\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    last_login_at\n    \n as \n    \n    last_login_at\n    \n, \n    \n    \n    locale\n    \n as \n    \n    locale\n    \n, \n    \n    \n    locale_id\n    \n as \n    \n    locale_id\n    \n, \n    \n    \n    moderator\n    \n as \n    \n    moderator\n    \n, \n    \n    \n    name\n    \n as \n    \n    name\n    \n, \n    \n    \n    notes\n    \n as \n    \n    notes\n    \n, \n    \n    \n    only_private_comments\n    \n as \n    \n    only_private_comments\n    \n, \n    \n    \n    organization_id\n    \n as \n    \n    organization_id\n    \n, \n    \n    \n    phone\n    \n as \n    \n    phone\n    \n, \n    \n    \n    remote_photo_url\n    \n as \n    \n    remote_photo_url\n    \n, \n    \n    \n    restricted_agent\n    \n as \n    \n    restricted_agent\n    \n, \n    \n    \n    role\n    \n as \n    \n    role\n    \n, \n    \n    \n    shared\n    \n as \n    \n    shared\n    \n, \n    \n    \n    shared_agent\n    \n as \n    \n    shared_agent\n    \n, \n    \n    \n    signature\n    \n as \n    \n    signature\n    \n, \n    \n    \n    suspended\n    \n as \n    \n    suspended\n    \n, \n    \n    \n    ticket_restriction\n    \n as \n    \n    ticket_restriction\n    \n, \n    \n    \n    time_zone\n    \n as \n    \n    time_zone\n    \n, \n    \n    \n    two_factor_auth_enabled\n    \n as \n    \n    two_factor_auth_enabled\n    \n, \n    \n    \n    updated_at\n    \n as \n    \n    updated_at\n    \n, \n    \n    \n    url\n    \n as \n    \n    url\n    \n, \n    \n    \n    verified\n    \n as \n    \n    verified\n    \n\n\n\n        \n    from base\n),\n\nfinal as ( \n    \n    select \n        id as user_id,\n        external_id,\n        _fivetran_synced,\n        last_login_at,\n            created_at,\n            updated_at,\n        \n        email,\n        name,\n        organization_id,\n        role,\n        ticket_restriction,\n        time_zone,\n        locale,\n        active as is_active,\n        suspended as is_suspended\n    from fields\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:37.100294Z", "completed_at": "2023-11-15T02:15:38.878210Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.886964Z", "completed_at": "2023-11-15T02:15:38.886972Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 1.7892098426818848, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__ticket_schedules", "compiled": true, "compiled_code": "\n\nwith ticket as (\n  \n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket\"\n\n), ticket_schedule as (\n \n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_schedule\"\n\n), schedule as (\n \n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__schedule\"\n\n\n), default_schedule_events as (\n-- Goal: understand the working schedules applied to tickets, so that we can then determine the applicable business hours/schedule.\n-- Your default schedule is used for all tickets, unless you set up a trigger to apply a specific schedule to specific tickets.\n\n-- This portion of the query creates ticket_schedules for these \"default\" schedules, as the ticket_schedule table only includes\n-- trigger schedules\n\n\n\n    \n\n    \n\n    \n\n  select\n    ticket.ticket_id,\n    ticket.created_at as schedule_created_at,\n    '360000310393' as schedule_id\n  from ticket\n  left join ticket_schedule as first_schedule\n    on first_schedule.ticket_id = ticket.ticket_id\n    and \n\n    first_schedule.created_at + ((interval '1 second') * (-5))\n\n <= ticket.created_at\n    and first_schedule.created_at >= ticket.created_at    \n  where first_schedule.ticket_id is null\n\n), schedule_events as (\n  \n  select\n    *\n  from default_schedule_events\n  \n  union all\n  \n  select \n    ticket_id,\n    created_at as schedule_created_at,\n    schedule_id\n  from ticket_schedule\n\n), ticket_schedules as (\n  \n  select \n    ticket_id,\n    schedule_id,\n    schedule_created_at,\n    coalesce(lead(schedule_created_at) over (partition by ticket_id order by schedule_created_at)\n            , \n\n    \n    current_timestamp::timestamp\n + ((interval '1 hour') * (1000))\n\n ) as schedule_invalidated_at\n  from schedule_events\n\n)\nselect\n  *\nfrom ticket_schedules", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_schedules\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.879700Z", "completed_at": "2023-11-15T02:15:38.887933Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.890306Z", "completed_at": "2023-11-15T02:15:38.890313Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.014374971389770508, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.not_null_stg_zendesk__user_user_id.102d572926", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect user_id\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user\"\nwhere user_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.883567Z", "completed_at": "2023-11-15T02:15:38.888250Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.890634Z", "completed_at": "2023-11-15T02:15:38.890641Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.014421939849853516, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk_source.unique_stg_zendesk__user_user_id.3d3e346b11", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    user_id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user\"\nwhere user_id is not null\ngroup by user_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.899595Z", "completed_at": "2023-11-15T02:15:38.929172Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.940713Z", "completed_at": "2023-11-15T02:15:38.940719Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.04442286491394043, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__reply_time_business_hours", "compiled": true, "compiled_code": "\n\n-- step 3, determine when an SLA will breach for SLAs that are in business hours\n\nwith ticket_schedules as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_schedules\"\n\n), schedule as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__schedule_spine\"\n\n), sla_policy_applied as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__sla_policy_applied\"\n\n\n), schedule_business_hours as (\n\n  select \n    schedule_id,\n    sum(end_time - start_time) as total_schedule_weekly_business_minutes\n  -- referring to stg_zendesk__schedule instead of int_zendesk__schedule_spine just to calculate total minutes\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__schedule\"\n  group by 1\n\n), ticket_sla_applied_with_schedules as (\n\n  select \n    sla_policy_applied.*,\n    ticket_schedules.schedule_id,\n    (\n        (\n        (\n        (\n        ((cast(sla_policy_applied.sla_applied_at as timestamp))::date - (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    sla_policy_applied.sla_applied_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::date)\n     * 24 + date_part('hour', (cast(sla_policy_applied.sla_applied_at as timestamp))::timestamp) - date_part('hour', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    sla_policy_applied.sla_applied_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + date_part('minute', (cast(sla_policy_applied.sla_applied_at as timestamp))::timestamp) - date_part('minute', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    sla_policy_applied.sla_applied_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + floor(date_part('second', (cast(sla_policy_applied.sla_applied_at as timestamp))::timestamp)) - floor(date_part('second', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    sla_policy_applied.sla_applied_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp)))\n     /60\n          ) as start_time_in_minutes_from_week,\n      schedule_business_hours.total_schedule_weekly_business_minutes,\n    -- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    sla_policy_applied.sla_applied_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date) as start_week_date\n\n  from sla_policy_applied\n  left join ticket_schedules on sla_policy_applied.ticket_id = ticket_schedules.ticket_id\n    and \n\n    ticket_schedules.schedule_created_at + ((interval '1 second') * (-1))\n\n <= sla_policy_applied.sla_applied_at\n    and \n\n    ticket_schedules.schedule_invalidated_at + ((interval '1 second') * (-1))\n\n > sla_policy_applied.sla_applied_at\n  left join schedule_business_hours \n    on ticket_schedules.schedule_id = schedule_business_hours.schedule_id\n  where sla_policy_applied.in_business_hours\n    and metric in ('next_reply_time', 'first_reply_time')\n  \n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_sla_applied as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_sla_applied_with_schedules.*,\n      cast(generated_number - 1 as integer) as week_number\n\n    from ticket_sla_applied_with_schedules\n    cross join weeks\n    where \n    ceiling(target/total_schedule_weekly_business_minutes)\n\n >= generated_number - 1\n\n), weekly_periods as (\n  \n  select \n    weeks_cross_ticket_sla_applied.*,\n    cast(greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as integer) as ticket_week_start_time,\n    cast((7*24*60) as integer) as ticket_week_end_time\n  from weeks_cross_ticket_sla_applied\n\n), intercepted_periods as (\n\n  select \n    weekly_periods.*,\n    schedule.start_time_utc as schedule_start_time,\n    schedule.end_time_utc as schedule_end_time,\n    (schedule.end_time_utc - greatest(ticket_week_start_time,schedule.start_time_utc)) as lapsed_business_minutes,\n    sum(schedule.end_time_utc - greatest(ticket_week_start_time,schedule.start_time_utc)) over \n      (partition by ticket_id, metric, sla_applied_at \n        order by week_number, schedule.start_time_utc\n        rows between unbounded preceding and current row) as sum_lapsed_business_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    -- We have everything calculated within a week, so take us to the appropriate week first by adding the week_number * minutes-in-a-week to the minute-mark where we start and stop counting for the week\n    and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_end_time))\n\n as timestamp) > cast(schedule.valid_from as timestamp)\n    and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_start_time))\n\n as timestamp) < cast(schedule.valid_until as timestamp)\n\n), intercepted_periods_with_breach_flag as (\n  \n  select \n    *,\n    target - sum_lapsed_business_minutes as remaining_minutes,\n    case when (target - sum_lapsed_business_minutes) < 0 \n      and \n        (lag(target - sum_lapsed_business_minutes) over\n        (partition by ticket_id, metric, sla_applied_at order by week_number, schedule_start_time) >= 0 \n        or \n        lag(target - sum_lapsed_business_minutes) over\n        (partition by ticket_id, metric, sla_applied_at order by week_number, schedule_start_time) is null) \n        then true else false end as is_breached_during_schedule -- this flags the scheduled period on which the breach took place\n  from intercepted_periods\n\n), intercepted_periods_with_breach_flag_calculated as (\n\n  select\n    *,\n    schedule_end_time + remaining_minutes as breached_at_minutes,\n    date_trunc('week', sla_applied_at) as starting_point,\n    \n\n    cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    sla_applied_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date) as timestamp) + ((interval '1 minute') * (cast(((7*24*60) * week_number) + (schedule_end_time + remaining_minutes) as integer )))\n\n as sla_breach_at,\n    \n\n    cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    sla_applied_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date) as timestamp) + ((interval '1 minute') * (cast(((7*24*60) * week_number) + (schedule_start_time) as integer )))\n\n as sla_schedule_start_at,\n    \n\n    cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    sla_applied_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date) as timestamp) + ((interval '1 minute') * (cast(((7*24*60) * week_number) + (schedule_end_time) as integer )))\n\n as sla_schedule_end_at,\n    cast(\n\n    -- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    sla_applied_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date) + ((interval '1 day') * (6))\n\n as date) as week_end_date\n  from intercepted_periods_with_breach_flag\n\n), reply_time_business_hours_sla as (\n\n  select\n    ticket_id,\n    sla_policy_name,\n    metric,\n    ticket_created_at,\n    sla_applied_at,\n    greatest(sla_applied_at,sla_schedule_start_at) as sla_schedule_start_at,\n    sla_schedule_end_at,\n    target,\n    sum_lapsed_business_minutes,\n    in_business_hours,\n    sla_breach_at,\n    is_breached_during_schedule\n  from intercepted_periods_with_breach_flag_calculated\n\n) \n\nselect * \nfrom reply_time_business_hours_sla", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__reply_time_business_hours\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.930352Z", "completed_at": "2023-11-15T02:15:38.942483Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:38.955989Z", "completed_at": "2023-11-15T02:15:38.956006Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.028705120086669922, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__agent_work_time_business_hours", "compiled": true, "compiled_code": "\n\n-- AGENT WORK TIME\n-- This is complicated, as SLAs minutes are only counted while the ticket is in 'new' or 'open' status.\n\n-- Additionally, for business hours, only 'new' or 'open' status hours are counted if they are also during business hours\nwith agent_work_time_filtered_statuses as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__agent_work_time_filtered_statuses\"\n  where in_business_hours\n\n), schedule as (\n\n  select * \n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__schedule_spine\"\n\n), ticket_schedules as (\n\n  select * \n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_schedules\"\n  \n-- cross schedules with work time\n), ticket_status_crossed_with_schedule as (\n  \n    select\n      agent_work_time_filtered_statuses.ticket_id,\n      agent_work_time_filtered_statuses.sla_applied_at,\n      agent_work_time_filtered_statuses.target,    \n      agent_work_time_filtered_statuses.sla_policy_name,    \n      ticket_schedules.schedule_id,\n\n      -- take the intersection of the intervals in which the status and the schedule were both active, for calculating the business minutes spent working on the ticket\n      greatest(valid_starting_at, schedule_created_at) as valid_starting_at,\n      least(valid_ending_at, schedule_invalidated_at) as valid_ending_at,\n\n      -- bringing the following in the determine which schedule (Daylight Savings vs Standard time) to use\n      valid_starting_at as status_valid_starting_at,\n      valid_ending_at as status_valid_ending_at\n\n    from agent_work_time_filtered_statuses\n    left join ticket_schedules\n      on agent_work_time_filtered_statuses.ticket_id = ticket_schedules.ticket_id\n    where \n        (\n        (\n        (\n        ((least(valid_ending_at, schedule_invalidated_at))::date - (greatest(valid_starting_at, schedule_created_at))::date)\n     * 24 + date_part('hour', (least(valid_ending_at, schedule_invalidated_at))::timestamp) - date_part('hour', (greatest(valid_starting_at, schedule_created_at))::timestamp))\n     * 60 + date_part('minute', (least(valid_ending_at, schedule_invalidated_at))::timestamp) - date_part('minute', (greatest(valid_starting_at, schedule_created_at))::timestamp))\n     * 60 + floor(date_part('second', (least(valid_ending_at, schedule_invalidated_at))::timestamp)) - floor(date_part('second', (greatest(valid_starting_at, schedule_created_at))::timestamp)))\n     > 0\n\n), ticket_full_solved_time as (\n\n    select \n      ticket_id,\n      sla_applied_at,\n      target,    \n      sla_policy_name,    \n      schedule_id,\n      valid_starting_at,\n      valid_ending_at,\n      status_valid_starting_at,\n      status_valid_ending_at,\n      (\n        (\n        (\n        (\n        ((cast(ticket_status_crossed_with_schedule.valid_starting_at as timestamp))::date - (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.valid_starting_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::date)\n     * 24 + date_part('hour', (cast(ticket_status_crossed_with_schedule.valid_starting_at as timestamp))::timestamp) - date_part('hour', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.valid_starting_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + date_part('minute', (cast(ticket_status_crossed_with_schedule.valid_starting_at as timestamp))::timestamp) - date_part('minute', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.valid_starting_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + floor(date_part('second', (cast(ticket_status_crossed_with_schedule.valid_starting_at as timestamp))::timestamp)) - floor(date_part('second', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.valid_starting_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp)))\n     /60\n            ) as valid_starting_at_in_minutes_from_week,\n        (\n        (\n        (\n        (\n        ((ticket_status_crossed_with_schedule.valid_ending_at)::date - (ticket_status_crossed_with_schedule.valid_starting_at)::date)\n     * 24 + date_part('hour', (ticket_status_crossed_with_schedule.valid_ending_at)::timestamp) - date_part('hour', (ticket_status_crossed_with_schedule.valid_starting_at)::timestamp))\n     * 60 + date_part('minute', (ticket_status_crossed_with_schedule.valid_ending_at)::timestamp) - date_part('minute', (ticket_status_crossed_with_schedule.valid_starting_at)::timestamp))\n     * 60 + floor(date_part('second', (ticket_status_crossed_with_schedule.valid_ending_at)::timestamp)) - floor(date_part('second', (ticket_status_crossed_with_schedule.valid_starting_at)::timestamp)))\n     /60\n              ) as raw_delta_in_minutes,\n    -- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.valid_starting_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date) as start_week_date\n              \n    from ticket_status_crossed_with_schedule\n    group by 1,2,3,4,5,6,7,8,9,10\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_full_solved_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n      ticket_full_solved_time.*,\n      cast(generated_number - 1 as integer) as week_number\n    from ticket_full_solved_time\n    cross join weeks\n    where floor((valid_starting_at_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number -1\n\n), weekly_period_agent_work_time as (\n\n    select \n\n      ticket_id,\n      sla_applied_at,\n      valid_starting_at,\n      valid_ending_at,\n      status_valid_starting_at,\n      status_valid_ending_at,\n      target,\n      sla_policy_name,\n      valid_starting_at_in_minutes_from_week,\n      raw_delta_in_minutes,\n      week_number,\n      schedule_id,\n      start_week_date,\n      cast(greatest(0, valid_starting_at_in_minutes_from_week - week_number * (7*24*60)) as integer) as ticket_week_start_time_minute,\n      cast(least(valid_starting_at_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as integer) as ticket_week_end_time_minute\n    \n    from weeks_cross_ticket_full_solved_time\n\n), intercepted_periods_agent as (\n  \n    select \n      weekly_period_agent_work_time.ticket_id,\n      weekly_period_agent_work_time.sla_applied_at,\n      weekly_period_agent_work_time.target,\n      weekly_period_agent_work_time.sla_policy_name,\n      weekly_period_agent_work_time.valid_starting_at,\n      weekly_period_agent_work_time.valid_ending_at,\n      weekly_period_agent_work_time.week_number,\n      weekly_period_agent_work_time.ticket_week_start_time_minute,\n      weekly_period_agent_work_time.ticket_week_end_time_minute,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time_minute, schedule.end_time_utc) - greatest(weekly_period_agent_work_time.ticket_week_start_time_minute, schedule.start_time_utc) as scheduled_minutes\n    from weekly_period_agent_work_time\n    join schedule on ticket_week_start_time_minute <= schedule.end_time_utc \n      and ticket_week_end_time_minute >= schedule.start_time_utc\n      and weekly_period_agent_work_time.schedule_id = schedule.schedule_id\n      -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n      -- We have everything calculated within a week, so take us to the appropriate week first by adding the week_number * minutes-in-a-week to the minute-mark where we start and stop counting for the week\n      and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_end_time_minute))\n\n as timestamp) > cast(schedule.valid_from as timestamp)\n      and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_start_time_minute))\n\n as timestamp) < cast(schedule.valid_until as timestamp)\n\n), intercepted_periods_with_running_total as (\n  \n    select \n      *,\n      sum(scheduled_minutes) over \n        (partition by ticket_id, sla_applied_at \n          order by valid_starting_at, week_number, schedule_end_time\n          rows between unbounded preceding and current row)\n        as running_total_scheduled_minutes\n\n    from intercepted_periods_agent\n\n\n), intercepted_periods_agent_with_breach_flag as (\n  select \n    intercepted_periods_with_running_total.*,\n    target - running_total_scheduled_minutes as remaining_target_minutes,\n    lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) as lag_check,\n    case when (target - running_total_scheduled_minutes) = 0 then true\n       when (target - running_total_scheduled_minutes) < 0 \n        and \n          (lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) > 0 \n          or \n          lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) is null) \n          then true else false end as is_breached_during_schedule\n          \n  from  intercepted_periods_with_running_total\n\n), intercepted_periods_agent_filtered as (\n\n  select\n    *,\n    (remaining_target_minutes + scheduled_minutes) as breach_minutes,\n    greatest(ticket_week_start_time_minute, schedule_start_time) + (remaining_target_minutes + scheduled_minutes) as breach_minutes_from_week\n  from intercepted_periods_agent_with_breach_flag\n  \n), agent_work_business_breach as (\n  \n  select \n    *,\n    \n\n    date_trunc('week', valid_starting_at) + ((interval '1 minute') * (cast(((7*24*60) * week_number) + breach_minutes_from_week as integer )))\n\n as sla_breach_at\n  from intercepted_periods_agent_filtered\n\n)\n\nselect * \nfrom agent_work_business_breach", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__agent_work_time_business_hours\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:38.943817Z", "completed_at": "2023-11-15T02:15:38.969994Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.015679Z", "completed_at": "2023-11-15T02:15:39.015692Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.07600593566894531, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__requester_wait_time_business_hours", "compiled": true, "compiled_code": "\n\n-- REQUESTER WAIT TIME\n-- This is complicated, as SLAs minutes are only counted while the ticket is in 'new', 'open', and 'on-hold' status.\n\n-- Additionally, for business hours, only 'new', 'open', and 'on-hold' status hours are counted if they are also during business hours\nwith requester_wait_time_filtered_statuses as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__requester_wait_time_filtered_statuses\"\n  where in_business_hours\n\n), schedule as (\n\n  select * \n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__schedule_spine\"\n\n), ticket_schedules as (\n\n  select * \n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_schedules\"\n  \n-- cross schedules with work time\n), ticket_status_crossed_with_schedule as (\n  \n    select\n      requester_wait_time_filtered_statuses.ticket_id,\n      requester_wait_time_filtered_statuses.sla_applied_at,\n      requester_wait_time_filtered_statuses.target,\n      requester_wait_time_filtered_statuses.sla_policy_name,\n      ticket_schedules.schedule_id,\n\n      -- take the intersection of the intervals in which the status and the schedule were both active, for calculating the business minutes spent working on the ticket\n      greatest(valid_starting_at, schedule_created_at) as valid_starting_at,\n      least(valid_ending_at, schedule_invalidated_at) as valid_ending_at,\n\n      -- bringing the following in the determine which schedule (Daylight Savings vs Standard time) to use\n      valid_starting_at as status_valid_starting_at,\n      valid_ending_at as status_valid_ending_at\n\n    from requester_wait_time_filtered_statuses\n    left join ticket_schedules\n      on requester_wait_time_filtered_statuses.ticket_id = ticket_schedules.ticket_id\n    where \n        (\n        (\n        (\n        ((least(valid_ending_at, schedule_invalidated_at))::date - (greatest(valid_starting_at, schedule_created_at))::date)\n     * 24 + date_part('hour', (least(valid_ending_at, schedule_invalidated_at))::timestamp) - date_part('hour', (greatest(valid_starting_at, schedule_created_at))::timestamp))\n     * 60 + date_part('minute', (least(valid_ending_at, schedule_invalidated_at))::timestamp) - date_part('minute', (greatest(valid_starting_at, schedule_created_at))::timestamp))\n     * 60 + floor(date_part('second', (least(valid_ending_at, schedule_invalidated_at))::timestamp)) - floor(date_part('second', (greatest(valid_starting_at, schedule_created_at))::timestamp)))\n     > 0\n\n), ticket_full_solved_time as (\n\n    select \n      ticket_id,\n      sla_applied_at,\n      target,\n      sla_policy_name,\n      schedule_id,\n      valid_starting_at,\n      valid_ending_at,\n      status_valid_starting_at,\n      status_valid_ending_at,\n      (\n        (\n        (\n        (\n        ((cast(ticket_status_crossed_with_schedule.valid_starting_at as timestamp))::date - (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.valid_starting_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::date)\n     * 24 + date_part('hour', (cast(ticket_status_crossed_with_schedule.valid_starting_at as timestamp))::timestamp) - date_part('hour', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.valid_starting_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + date_part('minute', (cast(ticket_status_crossed_with_schedule.valid_starting_at as timestamp))::timestamp) - date_part('minute', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.valid_starting_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + floor(date_part('second', (cast(ticket_status_crossed_with_schedule.valid_starting_at as timestamp))::timestamp)) - floor(date_part('second', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.valid_starting_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp)))\n     /60\n          ) as valid_starting_at_in_minutes_from_week,\n      (\n        (\n        (\n        (\n        ((ticket_status_crossed_with_schedule.valid_ending_at)::date - (ticket_status_crossed_with_schedule.valid_starting_at)::date)\n     * 24 + date_part('hour', (ticket_status_crossed_with_schedule.valid_ending_at)::timestamp) - date_part('hour', (ticket_status_crossed_with_schedule.valid_starting_at)::timestamp))\n     * 60 + date_part('minute', (ticket_status_crossed_with_schedule.valid_ending_at)::timestamp) - date_part('minute', (ticket_status_crossed_with_schedule.valid_starting_at)::timestamp))\n     * 60 + floor(date_part('second', (ticket_status_crossed_with_schedule.valid_ending_at)::timestamp)) - floor(date_part('second', (ticket_status_crossed_with_schedule.valid_starting_at)::timestamp)))\n     /60\n            ) as raw_delta_in_minutes,\n    -- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.valid_starting_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date) as start_week_date\n\n    from ticket_status_crossed_with_schedule\n    group by 1,2,3,4,5,6,7,8,9,10\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_full_solved_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n      ticket_full_solved_time.*,\n      cast(generated_number - 1 as integer) as week_number\n    from ticket_full_solved_time\n    cross join weeks\n    where floor((valid_starting_at_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number -1\n\n), weekly_period_requester_wait_time as (\n\n    select \n\n      ticket_id,\n      sla_applied_at,\n      valid_starting_at,\n      valid_ending_at,\n      status_valid_starting_at,\n      status_valid_ending_at,\n      target,\n      sla_policy_name,\n      valid_starting_at_in_minutes_from_week,\n      raw_delta_in_minutes,\n      week_number,\n      schedule_id,\n      start_week_date,\n      cast(greatest(0, valid_starting_at_in_minutes_from_week - week_number * (7*24*60)) as integer) as ticket_week_start_time_minute,\n      cast(least(valid_starting_at_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as integer) as ticket_week_end_time_minute\n    \n    from weeks_cross_ticket_full_solved_time\n\n), intercepted_periods_agent as (\n  \n    select \n      weekly_period_requester_wait_time.ticket_id,\n      weekly_period_requester_wait_time.sla_applied_at,\n      weekly_period_requester_wait_time.target,\n      weekly_period_requester_wait_time.sla_policy_name,\n      weekly_period_requester_wait_time.valid_starting_at,\n      weekly_period_requester_wait_time.valid_ending_at,\n      weekly_period_requester_wait_time.week_number,\n      weekly_period_requester_wait_time.ticket_week_start_time_minute,\n      weekly_period_requester_wait_time.ticket_week_end_time_minute,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time_minute, schedule.end_time_utc) - greatest(weekly_period_requester_wait_time.ticket_week_start_time_minute, schedule.start_time_utc) as scheduled_minutes\n    from weekly_period_requester_wait_time\n    join schedule on ticket_week_start_time_minute <= schedule.end_time_utc \n      and ticket_week_end_time_minute >= schedule.start_time_utc\n      and weekly_period_requester_wait_time.schedule_id = schedule.schedule_id\n      -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n      -- We have everything calculated within a week, so take us to the appropriate week first by adding the week_number * minutes-in-a-week to the minute-mark where we start and stop counting for the week\n      and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_end_time_minute))\n\n as timestamp) > cast(schedule.valid_from as timestamp)\n      and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_start_time_minute))\n\n as timestamp) < cast(schedule.valid_until as timestamp)\n  \n), intercepted_periods_with_running_total as (\n  \n    select \n      *,\n      sum(scheduled_minutes) over \n        (partition by ticket_id, sla_applied_at \n          order by valid_starting_at, week_number, schedule_end_time\n          rows between unbounded preceding and current row)\n        as running_total_scheduled_minutes\n\n    from intercepted_periods_agent\n\n\n), intercepted_periods_agent_with_breach_flag as (\n  select \n    intercepted_periods_with_running_total.*,\n    target - running_total_scheduled_minutes as remaining_target_minutes,\n    lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) as lag_check,\n    case when (target - running_total_scheduled_minutes) = 0 then true\n       when (target - running_total_scheduled_minutes) < 0 \n        and \n          (lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) > 0 \n          or \n          lag(target - running_total_scheduled_minutes) over\n          (partition by ticket_id, sla_applied_at order by valid_starting_at, week_number, schedule_end_time) is null) \n          then true else false end as is_breached_during_schedule\n          \n  from  intercepted_periods_with_running_total\n\n), intercepted_periods_agent_filtered as (\n\n  select\n    *,\n    (remaining_target_minutes + scheduled_minutes) as breach_minutes,\n    greatest(ticket_week_start_time_minute, schedule_start_time) + (remaining_target_minutes + scheduled_minutes) as breach_minutes_from_week\n  from intercepted_periods_agent_with_breach_flag\n\n), requester_wait_business_breach as (\n  \n  select \n    *,\n    \n\n    date_trunc('week', valid_starting_at) + ((interval '1 minute') * (cast(((7*24*60) * week_number) + breach_minutes_from_week as integer )))\n\n as sla_breach_at\n  from intercepted_periods_agent_filtered\n\n)\n\nselect * \nfrom requester_wait_business_breach", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__requester_wait_time_business_hours\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:39.086800Z", "completed_at": "2023-11-15T02:15:39.115482Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.117339Z", "completed_at": "2023-11-15T02:15:39.117347Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.034806013107299805, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__comment_metrics", "compiled": true, "compiled_code": "with  __dbt__cte__int_zendesk__comments_enriched as (\nwith ticket_comment as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__updates\"\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user\"\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commenter roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at, commenter_role)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role\n), ticket_comments as (\n\n    select *\n    from __dbt__cte__int_zendesk__comments_enriched\n),\n\ncomment_counts as (\n    select\n        ticket_id,\n        last_comment_added_at,\n        sum(case when commenter_role = 'internal_comment' and is_public = true\n            then 1\n            else 0\n                end) as count_public_agent_comments,\n        sum(case when commenter_role = 'internal_comment'\n            then 1\n            else 0\n                end) as count_agent_comments,\n        sum(case when commenter_role = 'external_comment'\n            then 1\n            else 0\n                end) as count_end_user_comments,\n        sum(case when is_public = true\n            then 1\n            else 0\n                end) as count_public_comments,\n        sum(case when is_public = false\n            then 1\n            else 0\n                end) as count_internal_comments,\n        count(*) as total_comments,\n        count(distinct case when commenter_role = 'internal_comment'\n            then user_id\n                end) as count_ticket_handoffs,\n        sum(case when commenter_role = 'internal_comment' and is_public = true and previous_commenter_role != 'first_comment'\n            then 1\n            else 0\n                end) as count_agent_replies\n    from ticket_comments\n\n    group by 1, 2\n),\n\nfinal as (\n    select\n        *,\n        count_public_agent_comments = 1 as is_one_touch_resolution,\n        count_public_agent_comments = 2 as is_two_touch_resolution\n    from comment_counts\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__comment_metrics\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:36.802036Z", "completed_at": "2023-11-15T02:15:39.086483Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.114508Z", "completed_at": "2023-11-15T02:15:39.114515Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 2.58089280128479, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk_source.stg_zendesk__user_tag", "compiled": true, "compiled_code": "--To disable this model, set the using_user_tags variable within your dbt_project.yml file to False.\n\n\nwith base as (\n\n    select * \n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user_tag_tmp\"\n\n),\n\nfields as (\n\n    select\n        /*\n        The below macro is used to generate the correct SQL for package staging models. It takes a list of columns \n        that are expected/needed (staging_columns from dbt_zendesk_source/models/tmp/) and compares it with columns \n        in the source (source_columns from dbt_zendesk_source/macros/).\n        For more information refer to our dbt_fivetran_utils documentation (https://github.com/fivetran/dbt_fivetran_utils.git).\n        */\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    user_id\n    \n as \n    \n    user_id\n    \n, \n    \n    \n    tag\n    \n as \n    \n    tag\n    \n\n\n\n        \n    from base\n),\n\nfinal as (\n    \n    select \n        user_id,\n        \n        tag\n        \n        as tags\n    from fields\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user_tag\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:39.381368Z", "completed_at": "2023-11-15T02:15:39.386943Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.387642Z", "completed_at": "2023-11-15T02:15:39.387648Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.007601022720336914, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__user_aggregates", "compiled": true, "compiled_code": "with users as (\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user\"\n\n--If you use user tags this will be included, if not it will be ignored.\n\n), user_tags as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user_tag\"\n  \n), user_tag_aggregate as (\n  select\n    user_tags.user_id,\n    \n    string_agg(user_tags.tags, ', ')\n\n as user_tags\n  from user_tags\n  group by 1\n\n\n\n), final as (\n  select \n    users.*\n\n    --If you use user tags this will be included, if not it will be ignored.\n    \n    ,user_tag_aggregate.user_tags\n    \n  from users\n\n  --If you use user tags this will be included, if not it will be ignored.\n  \n  left join user_tag_aggregate\n    using(user_id)\n  \n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__user_aggregates\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:39.395524Z", "completed_at": "2023-11-15T02:15:39.410299Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.412575Z", "completed_at": "2023-11-15T02:15:39.412583Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.023554086685180664, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.zendesk__ticket_enriched", "compiled": true, "compiled_code": "-- this model enriches the ticket table with ticket-related dimensions.  This table will not include any metrics.\n-- for metrics, see ticket_metrics!\n\nwith ticket as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_aggregates\"\n\n--If you use using_ticket_form_history this will be included, if not it will be ignored.\n\n), latest_ticket_form as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__latest_ticket_form\"\n\n\n), latest_satisfaction_ratings as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_historical_satisfaction\"\n\n), users as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__user_aggregates\"\n\n), requester_updates as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__requester_updates\"\n\n), assignee_updates as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__assignee_updates\"\n\n), ticket_group as (\n    \n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__group\"\n\n), organization as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__organization_aggregates\"\n\n), joined as (\n\n    select \n\n        ticket.*,\n\n        --If you use using_ticket_form_history this will be included, if not it will be ignored.\n        \n        latest_ticket_form.name as ticket_form_name,\n        \n\n        latest_satisfaction_ratings.count_satisfaction_scores as ticket_total_satisfaction_scores,\n        latest_satisfaction_ratings.first_satisfaction_score as ticket_first_satisfaction_score,\n        latest_satisfaction_ratings.latest_satisfaction_score as ticket_satisfaction_score,\n        latest_satisfaction_ratings.latest_satisfaction_comment as ticket_satisfaction_comment,\n        latest_satisfaction_ratings.latest_satisfaction_reason as ticket_satisfaction_reason,\n        latest_satisfaction_ratings.is_good_to_bad_satisfaction_score,\n        latest_satisfaction_ratings.is_bad_to_good_satisfaction_score,\n\n        --If you use using_domain_names tags this will be included, if not it will be ignored.\n        \n        organization.domain_names as ticket_organization_domain_names,\n        requester_org.domain_names as requester_organization_domain_names,\n        \n\n        requester.external_id as requester_external_id,\n        requester.created_at as requester_created_at,\n        requester.updated_at as requester_updated_at,\n        requester.role as requester_role,\n        requester.email as requester_email,\n        requester.name as requester_name,\n        requester.is_active as is_requester_active,\n        requester.locale as requester_locale,\n        requester.time_zone as requester_time_zone,\n        coalesce(requester_updates.total_updates, 0) as requester_ticket_update_count,\n        requester_updates.last_updated as requester_ticket_last_update_at,\n        requester.last_login_at as requester_last_login_at,\n        requester.organization_id as requester_organization_id,\n        requester_org.name as requester_organization_name,\n\n        --If you use organization tags this will be included, if not it will be ignored.\n        \n        requester_org.organization_tags as requester_organization_tags,\n        \n        requester_org.external_id as requester_organization_external_id,\n        requester_org.created_at as requester_organization_created_at,\n        requester_org.updated_at as requester_organization_updated_at,\n        submitter.external_id as submitter_external_id,\n        submitter.role as submitter_role,\n        case when submitter.role in ('agent','admin') \n            then true \n            else false\n                end as is_agent_submitted,\n        submitter.email as submitter_email,\n        submitter.name as submitter_name,\n        submitter.is_active as is_submitter_active,\n        submitter.locale as submitter_locale,\n        submitter.time_zone as submitter_time_zone,\n        assignee.external_id as assignee_external_id,\n        assignee.role as assignee_role,\n        assignee.email as assignee_email,\n        assignee.name as assignee_name,\n        assignee.is_active as is_assignee_active,\n        assignee.locale as assignee_locale,\n        assignee.time_zone as assignee_time_zone,\n        coalesce(assignee_updates.total_updates, 0) as assignee_ticket_update_count,\n        assignee_updates.last_updated as assignee_ticket_last_update_at,\n        assignee.last_login_at as assignee_last_login_at,\n        ticket_group.name as group_name,\n        organization.name as organization_name\n\n        --If you use using_user_tags this will be included, if not it will be ignored.\n        \n        ,requester.user_tags as requester_tag,\n        submitter.user_tags as submitter_tag,\n        assignee.user_tags as assignee_tag\n        \n\n    \n    from ticket\n\n    --Requester Joins\n    join users as requester\n        on requester.user_id = ticket.requester_id\n\n    left join organization as requester_org\n        on requester_org.organization_id = requester.organization_id\n\n    left join requester_updates\n        on requester_updates.ticket_id = ticket.ticket_id\n            and requester_updates.requester_id = ticket.requester_id\n    \n    --Submitter Joins\n    join users as submitter\n        on submitter.user_id = ticket.submitter_id\n    \n    --Assignee Joins\n    left join users as assignee\n        on assignee.user_id = ticket.assignee_id\n\n    left join assignee_updates\n        on assignee_updates.ticket_id = ticket.ticket_id\n            and assignee_updates.assignee_id = ticket.assignee_id\n\n    --Ticket, Org, and Brand Joins\n    left join ticket_group\n        on ticket_group.group_id = ticket.group_id\n\n    --If you use using_ticket_form_history this will be included, if not it will be ignored.\n    \n    left join latest_ticket_form\n        on latest_ticket_form.ticket_form_id = ticket.ticket_form_id\n    \n\n    left join organization\n        on organization.organization_id = ticket.organization_id\n\n    left join latest_satisfaction_ratings\n        on latest_satisfaction_ratings.ticket_id = ticket.ticket_id\n)\n\nselect *\nfrom joined", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_enriched\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:39.400804Z", "completed_at": "2023-11-15T02:15:39.411248Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.413353Z", "completed_at": "2023-11-15T02:15:39.413356Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.023946046829223633, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__reply_time_combined", "compiled": true, "compiled_code": "with reply_time_calendar_hours_sla as (\n  \n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__reply_time_calendar_hours\"\n\n\n\n), reply_time_business_hours_sla as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__reply_time_business_hours\"\n\n\n\n), ticket_updates as (\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__updates\"\n\n), users as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__user_aggregates\"\n\n), reply_time_breached_at as (\n\n  select \n    ticket_id,\n    sla_policy_name,\n    metric,\n    ticket_created_at,\n    sla_applied_at,\n    sla_applied_at as sla_schedule_start_at,\n    cast(null as timestamp) as sla_schedule_end_at,\n    cast(null as numeric(28,6)) as sum_lapsed_business_minutes,\n    target,\n    in_business_hours,\n    sla_breach_at\n  from reply_time_calendar_hours_sla\n\n\n\n  union all\n\n  select \n    ticket_id,\n    sla_policy_name,\n    metric,\n    ticket_created_at,\n    sla_applied_at,\n    sla_schedule_start_at,\n    sla_schedule_end_at,\n    sum_lapsed_business_minutes,\n    target,\n    in_business_hours,\n    sla_breach_at\n  from reply_time_business_hours_sla\n\n\n-- Now that we have the breach time, see when the first reply after the sla policy was applied took place.\n), ticket_solved_times as (\n  select\n    ticket_id,\n    valid_starting_at as solved_at\n  from ticket_updates\n  where field_name = 'status'\n  and value in ('solved','closed')\n\n), reply_time as (\n  select \n    ticket_comment.ticket_id,\n    ticket_comment.valid_starting_at as reply_at,\n    commenter.role\n  from ticket_updates as ticket_comment\n  join users as commenter\n    on commenter.user_id = ticket_comment.user_id\n  where field_name = 'comment' \n    and ticket_comment.is_public\n    and commenter.role in ('agent','admin')\n\n), reply_time_breached_at_with_next_reply_timestamp as (\n\n  select \n    reply_time_breached_at.ticket_id,\n    reply_time_breached_at.sla_policy_name,\n    reply_time_breached_at.metric,\n    reply_time_breached_at.ticket_created_at,\n    reply_time_breached_at.sla_applied_at,\n    reply_time_breached_at.sum_lapsed_business_minutes,\n    reply_time_breached_at.target,\n    reply_time_breached_at.in_business_hours,\n    min(reply_time_breached_at.sla_schedule_start_at) as sla_schedule_start_at,\n    min(reply_time_breached_at.sla_schedule_end_at) as sla_schedule_end_at,\n    min(sla_breach_at) as sla_breach_at,\n    min(reply_at) as agent_reply_at,\n    min(solved_at) as next_solved_at\n  from reply_time_breached_at\n  left join reply_time\n    on reply_time.ticket_id = reply_time_breached_at.ticket_id\n    and reply_time.reply_at > reply_time_breached_at.sla_applied_at\n  left join ticket_solved_times\n    on reply_time_breached_at.ticket_id = ticket_solved_times.ticket_id\n    and ticket_solved_times.solved_at > reply_time_breached_at.sla_applied_at\n  group by 1,2,3,4,5,6,7,8\n\n), lagging_time_block as (\n  select\n    *,\n    lead(sla_schedule_start_at) over (partition by ticket_id, sla_policy_name, metric, sla_applied_at order by sla_schedule_start_at) as next_schedule_start,\n    min(sla_breach_at) over (partition by sla_policy_name, metric, sla_applied_at order by sla_schedule_start_at rows unbounded preceding) as first_sla_breach_at,\n\t\tcoalesce(lag(sum_lapsed_business_minutes) over (partition by sla_policy_name, metric, sla_applied_at order by sla_schedule_start_at), 0) as sum_lapsed_business_minutes_new\n  from reply_time_breached_at_with_next_reply_timestamp\n\n), filtered_reply_times as (\n  select\n    *\n  from lagging_time_block\n  where (\n    in_business_hours\n      and ((\n        agent_reply_at >= sla_schedule_start_at and agent_reply_at <= sla_schedule_end_at) -- ticket is replied to between a schedule window\n        or (agent_reply_at < sla_schedule_start_at and sum_lapsed_business_minutes_new = 0 and sla_breach_at = first_sla_breach_at) -- ticket is replied to before a schedule window and no business minutes have been spent on it\n        or (agent_reply_at is null and now() >= sla_schedule_start_at and now() < next_schedule_start) -- ticket is not replied to and therefore active. But only bring through the active SLA record that is most recent (after the last SLA schedule starts but before the next)  \n      ))\n    or not in_business_hours\n\n), reply_time_breached_at_remove_old_sla as (\n  select\n    *,\n    now() as current_time_check,\n    lead(sla_applied_at) over (partition by ticket_id, metric, in_business_hours order by sla_applied_at) as updated_sla_policy_starts_at,\n    case when \n      lead(sla_applied_at) over (partition by ticket_id, metric, in_business_hours order by sla_applied_at) --updated sla policy start at time\n      < sla_breach_at then true else false end as is_stale_sla_policy,\n    case when (sla_breach_at < agent_reply_at and sla_breach_at < next_solved_at)\n                or (sla_breach_at < agent_reply_at and next_solved_at is null)\n                or (agent_reply_at is null and sla_breach_at < next_solved_at)\n                or (agent_reply_at is null and next_solved_at is null)\n      then true\n      else false\n        end as is_sla_breached\n  from filtered_reply_times\n  \n), reply_time_breach as (\n  select \n    *,\n    case when \n        (\n        (\n        ((agent_reply_at)::date - (sla_schedule_start_at)::date)\n     * 24 + date_part('hour', (agent_reply_at)::timestamp) - date_part('hour', (sla_schedule_start_at)::timestamp))\n     * 60 + date_part('minute', (agent_reply_at)::timestamp) - date_part('minute', (sla_schedule_start_at)::timestamp))\n     < 0 \n      then 0 \n      else sum_lapsed_business_minutes_new + \n        (\n        (\n        ((coalesce(agent_reply_at, current_time_check))::date - (sla_schedule_start_at)::date)\n     * 24 + date_part('hour', (coalesce(agent_reply_at, current_time_check))::timestamp) - date_part('hour', (sla_schedule_start_at)::timestamp))\n     * 60 + date_part('minute', (coalesce(agent_reply_at, current_time_check))::timestamp) - date_part('minute', (sla_schedule_start_at)::timestamp))\n     \n    end as sla_elapsed_time\n  from reply_time_breached_at_remove_old_sla\n)\n\nselect *\nfrom reply_time_breach", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__reply_time_combined\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:39.426404Z", "completed_at": "2023-11-15T02:15:39.494983Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.497827Z", "completed_at": "2023-11-15T02:15:39.497834Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.07541012763977051, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk.not_null_zendesk__ticket_enriched_ticket_id.e3efc5bf0a", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect ticket_id\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_enriched\"\nwhere ticket_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:39.429858Z", "completed_at": "2023-11-15T02:15:39.495811Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.498717Z", "completed_at": "2023-11-15T02:15:39.498728Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.08473420143127441, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk.unique_zendesk__ticket_enriched_ticket_id.7c3c6ca9ef", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    ticket_id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_enriched\"\nwhere ticket_id is not null\ngroup by ticket_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:39.433551Z", "completed_at": "2023-11-15T02:15:39.497222Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.508477Z", "completed_at": "2023-11-15T02:15:39.508483Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.08537888526916504, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.zendesk__ticket_metrics", "compiled": true, "compiled_code": "with  __dbt__cte__int_zendesk__ticket_resolution_times_calendar as (\nwith historical_solved_status as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_historical_status\"\n    where status = 'solved'\n\n), ticket as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket\"\n\n), ticket_historical_assignee as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_historical_assignee\"\n\n), ticket_historical_group as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_historical_group\"\n\n), solved_times as (\n  \n  select\n  \n    ticket_id,\n    min(valid_starting_at) as first_solved_at,\n    max(valid_starting_at) as last_solved_at,\n    count(status) as solved_count \n\n  from historical_solved_status\n  group by 1\n\n)\n\n  select\n\n    ticket.ticket_id,\n    ticket.created_at,\n    solved_times.first_solved_at,\n    solved_times.last_solved_at,\n    ticket_historical_assignee.unique_assignee_count,\n    ticket_historical_assignee.assignee_stations_count,\n    ticket_historical_group.group_stations_count,\n    ticket_historical_assignee.first_assignee_id,\n    ticket_historical_assignee.last_assignee_id,\n    ticket_historical_assignee.first_agent_assignment_date,\n    ticket_historical_assignee.last_agent_assignment_date,\n    ticket_historical_assignee.ticket_unassigned_duration_calendar_minutes,\n    solved_times.solved_count as total_resolutions,\n    case when solved_times.solved_count <= 1\n      then 0\n      else solved_times.solved_count - 1 --subtracting one as the first solve is not a reopen.\n        end as count_reopens,\n\n    \n        (\n        (\n        ((solved_times.last_solved_at)::date - (ticket_historical_assignee.first_agent_assignment_date)::date)\n     * 24 + date_part('hour', (solved_times.last_solved_at)::timestamp) - date_part('hour', (ticket_historical_assignee.first_agent_assignment_date)::timestamp))\n     * 60 + date_part('minute', (solved_times.last_solved_at)::timestamp) - date_part('minute', (ticket_historical_assignee.first_agent_assignment_date)::timestamp))\n     as first_assignment_to_resolution_calendar_minutes,\n    \n        (\n        (\n        ((solved_times.last_solved_at)::date - (ticket_historical_assignee.last_agent_assignment_date)::date)\n     * 24 + date_part('hour', (solved_times.last_solved_at)::timestamp) - date_part('hour', (ticket_historical_assignee.last_agent_assignment_date)::timestamp))\n     * 60 + date_part('minute', (solved_times.last_solved_at)::timestamp) - date_part('minute', (ticket_historical_assignee.last_agent_assignment_date)::timestamp))\n     as last_assignment_to_resolution_calendar_minutes,\n    \n        (\n        (\n        ((solved_times.first_solved_at)::date - (ticket.created_at)::date)\n     * 24 + date_part('hour', (solved_times.first_solved_at)::timestamp) - date_part('hour', (ticket.created_at)::timestamp))\n     * 60 + date_part('minute', (solved_times.first_solved_at)::timestamp) - date_part('minute', (ticket.created_at)::timestamp))\n     as first_resolution_calendar_minutes,\n    \n        (\n        (\n        ((solved_times.last_solved_at)::date - (ticket.created_at)::date)\n     * 24 + date_part('hour', (solved_times.last_solved_at)::timestamp) - date_part('hour', (ticket.created_at)::timestamp))\n     * 60 + date_part('minute', (solved_times.last_solved_at)::timestamp) - date_part('minute', (ticket.created_at)::timestamp))\n     as final_resolution_calendar_minutes\n\n  from ticket\n\n  left join ticket_historical_assignee\n    using(ticket_id)\n\n  left join ticket_historical_group\n    using(ticket_id)\n\n  left join solved_times\n    using(ticket_id)\n),  __dbt__cte__int_zendesk__comments_enriched as (\nwith ticket_comment as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__updates\"\n    where field_name = 'comment'\n\n), users as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user\"\n\n), joined as (\n\n    select \n\n        ticket_comment.*,\n        case when commenter.role = 'end-user' then 'external_comment'\n            when commenter.role in ('agent','admin') then 'internal_comment'\n            else 'unknown' end as commenter_role\n    \n    from ticket_comment\n    \n    join users as commenter\n        on commenter.user_id = ticket_comment.user_id\n\n), add_previous_commenter_role as (\n    /*\n    In int_zendesk__ticket_reply_times we will only be focusing on reply times between public tickets.\n    The below union explicitly identifies the previous commenter roles of public and not public comments.\n    */\n    select\n        *,\n        coalesce(\n            lag(commenter_role) over (partition by ticket_id order by valid_starting_at, commenter_role)\n            , 'first_comment') \n            as previous_commenter_role\n    from joined\n    where is_public\n\n    union all\n\n    select\n        *,\n        'non_public_comment' as previous_commenter_role\n    from joined\n    where not is_public\n)\n\nselect \n    *,\n    first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_comment_added_at,\n    sum(case when not is_public then 1 else 0 end) over (partition by ticket_id order by valid_starting_at rows between unbounded preceding and current row) as previous_internal_comment_count\nfrom add_previous_commenter_role\n),  __dbt__cte__int_zendesk__ticket_reply_times as (\nwith ticket_public_comments as (\n\n    select *\n    from __dbt__cte__int_zendesk__comments_enriched\n    where is_public\n\n), end_user_comments as (\n  \n  select \n    ticket_id,\n    valid_starting_at as end_user_comment_created_at,\n    ticket_created_date,\n    commenter_role,\n    previous_internal_comment_count,\n    previous_commenter_role = 'first_comment' as is_first_comment\n  from ticket_public_comments \n  where (commenter_role = 'external_comment'\n    and ticket_public_comments.previous_commenter_role != 'external_comment') -- we only care about net new end user comments\n    or previous_commenter_role = 'first_comment' -- We also want to take into consideration internal first comment replies\n\n), reply_timestamps as (  \n\n  select\n    end_user_comments.ticket_id,\n    -- If the commentor was internal, a first comment, and had previous non public internal comments then we want the ticket created date to be the end user comment created date\n    -- Otherwise we will want to end user comment created date\n    case when is_first_comment then end_user_comments.ticket_created_date else end_user_comments.end_user_comment_created_at end as end_user_comment_created_at,\n    end_user_comments.is_first_comment,\n    min(case when is_first_comment \n        and end_user_comments.commenter_role != 'external_comment' \n        and (end_user_comments.previous_internal_comment_count > 0)\n          then end_user_comments.end_user_comment_created_at \n        else agent_comments.valid_starting_at end) as agent_responded_at\n  from end_user_comments\n  left join ticket_public_comments as agent_comments\n    on agent_comments.ticket_id = end_user_comments.ticket_id\n    and agent_comments.commenter_role = 'internal_comment'\n    and agent_comments.valid_starting_at > end_user_comments.end_user_comment_created_at\n  group by 1,2,3\n\n)\n\n  select\n    *,\n    (\n        (\n        (\n        (\n        ((agent_responded_at)::date - (end_user_comment_created_at)::date)\n     * 24 + date_part('hour', (agent_responded_at)::timestamp) - date_part('hour', (end_user_comment_created_at)::timestamp))\n     * 60 + date_part('minute', (agent_responded_at)::timestamp) - date_part('minute', (end_user_comment_created_at)::timestamp))\n     * 60 + floor(date_part('second', (agent_responded_at)::timestamp)) - floor(date_part('second', (end_user_comment_created_at)::timestamp)))\n     / 60) as reply_time_calendar_minutes\n  from reply_timestamps\n  order by 1,2\n),  __dbt__cte__int_zendesk__ticket_reply_times_calendar as (\nwith ticket as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket\"\n\n), ticket_reply_times as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_reply_times\n\n)\n\nselect\n\n  ticket.ticket_id,\n  sum(case when is_first_comment then reply_time_calendar_minutes\n    else null end) as first_reply_time_calendar_minutes,\n  sum(reply_time_calendar_minutes) as total_reply_time_calendar_minutes --total combined time the customer waits for internal response\n  \nfrom ticket\nleft join ticket_reply_times\n  using (ticket_id)\n\ngroup by 1\n),  __dbt__cte__int_zendesk__ticket_work_time_calendar as (\nwith ticket_historical_status as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_historical_status\"\n\n), calendar_minutes as (\n  \n    select \n        ticket_id,\n        status,\n        case when status in ('pending') then status_duration_calendar_minutes\n            else 0 end as agent_wait_time_in_minutes,\n        case when status in ('new', 'open', 'hold') then status_duration_calendar_minutes\n            else 0 end as requester_wait_time_in_minutes,\n        case when status in ('new', 'open', 'hold', 'pending') then status_duration_calendar_minutes \n            else 0 end as solve_time_in_minutes, \n        case when status in ('new', 'open') then status_duration_calendar_minutes\n            else 0 end as agent_work_time_in_minutes,\n        case when status in ('hold') then status_duration_calendar_minutes\n            else 0 end as on_hold_time_in_minutes,\n        case when status = 'new' then status_duration_calendar_minutes\n            else 0 end as new_status_duration_minutes,\n        case when status = 'open' then status_duration_calendar_minutes\n            else 0 end as open_status_duration_minutes,\n        case when status = 'deleted' then 1\n            else 0 end as ticket_deleted,\n        first_value(valid_starting_at) over (partition by ticket_id order by valid_starting_at desc, ticket_id rows unbounded preceding) as last_status_assignment_date,\n        case when lag(status) over (partition by ticket_id order by valid_starting_at) = 'deleted' and status != 'deleted'\n            then 1\n            else 0\n                end as ticket_recoveries\n\n    from ticket_historical_status\n\n)\n\nselect \n  ticket_id,\n  last_status_assignment_date,\n  sum(ticket_deleted) as ticket_deleted_count,\n  sum(agent_wait_time_in_minutes) as agent_wait_time_in_calendar_minutes,\n  sum(requester_wait_time_in_minutes) as requester_wait_time_in_calendar_minutes,\n  sum(solve_time_in_minutes) as solve_time_in_calendar_minutes,\n  sum(agent_work_time_in_minutes) as agent_work_time_in_calendar_minutes,\n  sum(on_hold_time_in_minutes) as on_hold_time_in_calendar_minutes,\n  sum(new_status_duration_minutes) as new_status_duration_in_calendar_minutes,\n  sum(open_status_duration_minutes) as open_status_duration_in_calendar_minutes,\n  sum(ticket_recoveries) as total_ticket_recoveries\nfrom calendar_minutes\ngroup by 1, 2\n),  __dbt__cte__int_zendesk__ticket_first_resolution_time_business as (\n\n\nwith ticket_resolution_times_calendar as (\n\n    select *\n    from __dbt__cte__int_zendesk__ticket_resolution_times_calendar\n\n), ticket_schedules as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_schedules\"\n\n), schedule as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__schedule_spine\"\n\n), ticket_first_resolution_time as (\n\n  select \n    ticket_resolution_times_calendar.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(ticket_resolution_times_calendar.first_solved_at) as first_solved_at,\n\n    (\n        (\n        (\n        (\n        ((cast(ticket_schedules.schedule_created_at as timestamp))::date - (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::date)\n     * 24 + date_part('hour', (cast(ticket_schedules.schedule_created_at as timestamp))::timestamp) - date_part('hour', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + date_part('minute', (cast(ticket_schedules.schedule_created_at as timestamp))::timestamp) - date_part('minute', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + floor(date_part('second', (cast(ticket_schedules.schedule_created_at as timestamp))::timestamp)) - floor(date_part('second', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp)))\n     /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        \n        (\n        (\n        (\n        ((least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.first_solved_at)))::date - (ticket_schedules.schedule_created_at)::date)\n     * 24 + date_part('hour', (least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.first_solved_at)))::timestamp) - date_part('hour', (ticket_schedules.schedule_created_at)::timestamp))\n     * 60 + date_part('minute', (least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.first_solved_at)))::timestamp) - date_part('minute', (ticket_schedules.schedule_created_at)::timestamp))\n     * 60 + floor(date_part('second', (least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.first_solved_at)))::timestamp)) - floor(date_part('second', (ticket_schedules.schedule_created_at)::timestamp)))\n    /60\n        )) as raw_delta_in_minutes,\n    -- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date) as start_week_date\n      \n  from ticket_resolution_times_calendar\n  join ticket_schedules on ticket_resolution_times_calendar.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_first_resolution_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_first_resolution_time.*,\n      cast(generated_number - 1 as integer) as week_number\n\n    from ticket_first_resolution_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n\n), weekly_periods as (\n  \n    select \n\n      weeks_cross_ticket_first_resolution_time.*,\n      cast(greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as integer) as ticket_week_start_time,\n      cast(least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as integer) as ticket_week_end_time\n    \n    from weeks_cross_ticket_first_resolution_time\n\n), intercepted_periods as (\n\n  select ticket_id,\n         week_number,\n         weekly_periods.schedule_id,\n         ticket_week_start_time,\n         ticket_week_end_time,\n         schedule.start_time_utc as schedule_start_time,\n         schedule.end_time_utc as schedule_end_time,\n         least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    -- We have everything calculated within a week, so take us to the appropriate week first by adding the week_number * minutes-in-a-week to the minute-mark where we start and stop counting for the week\n    and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_end_time))\n\n as timestamp) > cast(schedule.valid_from as timestamp)\n    and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_start_time))\n\n as timestamp) < cast(schedule.valid_until as timestamp)\n\n)\n\n  select \n    ticket_id,\n    sum(scheduled_minutes) as first_resolution_business_minutes\n  from intercepted_periods\n  group by 1\n),  __dbt__cte__int_zendesk__ticket_full_resolution_time_business as (\n\n\nwith ticket_resolution_times_calendar as (\n\n    select *\n    from __dbt__cte__int_zendesk__ticket_resolution_times_calendar\n\n), ticket_schedules as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_schedules\"\n\n), schedule as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__schedule_spine\"\n\n), ticket_full_resolution_time as (\n\n  select \n    ticket_resolution_times_calendar.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(ticket_resolution_times_calendar.last_solved_at) as last_solved_at,\n    (\n        (\n        (\n        (\n        ((cast(ticket_schedules.schedule_created_at as timestamp))::date - (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::date)\n     * 24 + date_part('hour', (cast(ticket_schedules.schedule_created_at as timestamp))::timestamp) - date_part('hour', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + date_part('minute', (cast(ticket_schedules.schedule_created_at as timestamp))::timestamp) - date_part('minute', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + floor(date_part('second', (cast(ticket_schedules.schedule_created_at as timestamp))::timestamp)) - floor(date_part('second', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp)))\n     /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        \n        (\n        (\n        (\n        ((least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.last_solved_at)))::date - (ticket_schedules.schedule_created_at)::date)\n     * 24 + date_part('hour', (least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.last_solved_at)))::timestamp) - date_part('hour', (ticket_schedules.schedule_created_at)::timestamp))\n     * 60 + date_part('minute', (least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.last_solved_at)))::timestamp) - date_part('minute', (ticket_schedules.schedule_created_at)::timestamp))\n     * 60 + floor(date_part('second', (least(ticket_schedules.schedule_invalidated_at, min(ticket_resolution_times_calendar.last_solved_at)))::timestamp)) - floor(date_part('second', (ticket_schedules.schedule_created_at)::timestamp)))\n    /60\n        )) as raw_delta_in_minutes,\n    -- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date) as start_week_date\n      \n  from ticket_resolution_times_calendar\n  join ticket_schedules on ticket_resolution_times_calendar.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_full_resolution_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_full_resolution_time.*,\n      cast(generated_number - 1 as integer) as week_number\n\n    from ticket_full_resolution_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n), weekly_periods as (\n  \n  select \n\n    weeks_cross_ticket_full_resolution_time.*,\n    cast(greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as integer) as ticket_week_start_time,\n    cast(least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as integer) as ticket_week_end_time\n  \n  from weeks_cross_ticket_full_resolution_time\n\n), intercepted_periods as (\n\n  select \n    ticket_id,\n    week_number,\n    weekly_periods.schedule_id,\n    ticket_week_start_time,\n    ticket_week_end_time,\n    schedule.start_time_utc as schedule_start_time,\n    schedule.end_time_utc as schedule_end_time,\n    least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n    -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n    -- We have everything calculated within a week, so take us to the appropriate week first by adding the week_number * minutes-in-a-week to the minute-mark where we start and stop counting for the week\n    and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_end_time))\n\n as timestamp) > cast(schedule.valid_from as timestamp)\n    and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_start_time))\n\n as timestamp) < cast(schedule.valid_until as timestamp)\n  \n)\n\n  select \n    ticket_id,\n    sum(scheduled_minutes) as full_resolution_business_minutes\n  from intercepted_periods\n  group by 1\n),  __dbt__cte__int_zendesk__ticket_work_time_business as (\n\n\nwith ticket_historical_status as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_historical_status\"\n\n), ticket_schedules as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_schedules\"\n\n), schedule as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__schedule_spine\"\n\n), ticket_status_crossed_with_schedule as (\n  \n    select\n      ticket_historical_status.ticket_id,\n      ticket_historical_status.status as ticket_status,\n      ticket_schedules.schedule_id,\n\n      -- take the intersection of the intervals in which the status and the schedule were both active, for calculating the business minutes spent working on the ticket\n      greatest(valid_starting_at, schedule_created_at) as status_schedule_start,\n      least(valid_ending_at, schedule_invalidated_at) as status_schedule_end,\n\n      -- bringing the following in the determine which schedule (Daylight Savings vs Standard time) to use\n      ticket_historical_status.valid_starting_at as status_valid_starting_at,\n      ticket_historical_status.valid_ending_at as status_valid_ending_at\n\n    from ticket_historical_status\n    left join ticket_schedules\n      on ticket_historical_status.ticket_id = ticket_schedules.ticket_id\n      -- making sure there is indeed real overlap\n      where \n        (\n        (\n        (\n        ((least(valid_ending_at, schedule_invalidated_at))::date - (greatest(valid_starting_at, schedule_created_at))::date)\n     * 24 + date_part('hour', (least(valid_ending_at, schedule_invalidated_at))::timestamp) - date_part('hour', (greatest(valid_starting_at, schedule_created_at))::timestamp))\n     * 60 + date_part('minute', (least(valid_ending_at, schedule_invalidated_at))::timestamp) - date_part('minute', (greatest(valid_starting_at, schedule_created_at))::timestamp))\n     * 60 + floor(date_part('second', (least(valid_ending_at, schedule_invalidated_at))::timestamp)) - floor(date_part('second', (greatest(valid_starting_at, schedule_created_at))::timestamp)))\n     > 0\n\n), ticket_full_solved_time as (\n\n    select \n      ticket_id,\n      ticket_status,\n      schedule_id,\n      status_schedule_start,\n      status_schedule_end,\n      status_valid_starting_at,\n      status_valid_ending_at,\n    (\n        (\n        (\n        (\n        ((cast(ticket_status_crossed_with_schedule.status_schedule_start as timestamp))::date - (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.status_schedule_start + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::date)\n     * 24 + date_part('hour', (cast(ticket_status_crossed_with_schedule.status_schedule_start as timestamp))::timestamp) - date_part('hour', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.status_schedule_start + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + date_part('minute', (cast(ticket_status_crossed_with_schedule.status_schedule_start as timestamp))::timestamp) - date_part('minute', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.status_schedule_start + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + floor(date_part('second', (cast(ticket_status_crossed_with_schedule.status_schedule_start as timestamp))::timestamp)) - floor(date_part('second', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.status_schedule_start + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp)))\n     /60\n          ) as start_time_in_minutes_from_week,\n      (\n        (\n        (\n        (\n        ((ticket_status_crossed_with_schedule.status_schedule_end)::date - (ticket_status_crossed_with_schedule.status_schedule_start)::date)\n     * 24 + date_part('hour', (ticket_status_crossed_with_schedule.status_schedule_end)::timestamp) - date_part('hour', (ticket_status_crossed_with_schedule.status_schedule_start)::timestamp))\n     * 60 + date_part('minute', (ticket_status_crossed_with_schedule.status_schedule_end)::timestamp) - date_part('minute', (ticket_status_crossed_with_schedule.status_schedule_start)::timestamp))\n     * 60 + floor(date_part('second', (ticket_status_crossed_with_schedule.status_schedule_end)::timestamp)) - floor(date_part('second', (ticket_status_crossed_with_schedule.status_schedule_start)::timestamp)))\n     /60\n            ) as raw_delta_in_minutes,\n    -- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_status_crossed_with_schedule.status_schedule_start + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date) as start_week_date\n\n    from ticket_status_crossed_with_schedule\n    group by 1,2,3,4,5,6,7\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_full_solved_time as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n      ticket_full_solved_time.*,\n      cast(generated_number - 1 as integer) as week_number\n    from ticket_full_solved_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number -1\n\n), weekly_periods as (\n\n    select\n\n      weeks_cross_ticket_full_solved_time.*,\n      -- for each week, at what minute do we start counting?\n      cast(greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as integer) as ticket_week_start_time,\n      -- for each week, at what minute do we stop counting?\n      cast(least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as integer) as ticket_week_end_time\n    \n    from weeks_cross_ticket_full_solved_time\n\n), intercepted_periods as (\n  \n    select \n      weekly_periods.ticket_id,\n      weekly_periods.week_number,\n      weekly_periods.schedule_id,\n      weekly_periods.ticket_status,\n      weekly_periods.ticket_week_start_time,\n      weekly_periods.ticket_week_end_time,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time, schedule.end_time_utc) - greatest(weekly_periods.ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n    from weekly_periods\n    join schedule on \n      ticket_week_start_time <= schedule.end_time_utc \n      and ticket_week_end_time >= schedule.start_time_utc\n      and weekly_periods.schedule_id = schedule.schedule_id\n      -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n      -- We have everything calculated within a week, so take us to the appropriate week first by adding the week_number * minutes-in-a-week to the minute-mark where we start and stop counting for the week\n      and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_end_time))\n\n as timestamp) > cast(schedule.valid_from as timestamp)\n      and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_start_time))\n\n as timestamp) < cast(schedule.valid_until as timestamp)\n  \n), business_minutes as (\n  \n    select \n      ticket_id,\n      ticket_status,\n      case when ticket_status in ('pending') then scheduled_minutes\n          else 0 end as agent_wait_time_in_minutes,\n      case when ticket_status in ('new', 'open', 'hold') then scheduled_minutes\n          else 0 end as requester_wait_time_in_minutes,\n      case when ticket_status in ('new', 'open', 'hold', 'pending') then scheduled_minutes\n          else 0 end as solve_time_in_minutes,\n      case when ticket_status in ('new', 'open') then scheduled_minutes\n          else 0 end as agent_work_time_in_minutes,\n      case when ticket_status in ('hold') then scheduled_minutes\n          else 0 end as on_hold_time_in_minutes,\n      case when ticket_status = 'new' then scheduled_minutes\n          else 0 end as new_status_duration_minutes,\n      case when ticket_status = 'open' then scheduled_minutes\n          else 0 end as open_status_duration_minutes\n    from intercepted_periods\n\n)\n  \n    select \n      ticket_id,\n      sum(agent_wait_time_in_minutes) as agent_wait_time_in_business_minutes,\n      sum(requester_wait_time_in_minutes) as requester_wait_time_in_business_minutes,\n      sum(solve_time_in_minutes) as solve_time_in_business_minutes,\n      sum(agent_work_time_in_minutes) as agent_work_time_in_business_minutes,\n      sum(on_hold_time_in_minutes) as on_hold_time_in_business_minutes,\n      sum(new_status_duration_minutes) as new_status_duration_in_business_minutes,\n      sum(open_status_duration_minutes) as open_status_duration_in_business_minutes\n    from business_minutes\n    group by 1\n),  __dbt__cte__int_zendesk__ticket_first_reply_time_business as (\n\n\nwith ticket_reply_times as (\n\n    select *\n    from __dbt__cte__int_zendesk__ticket_reply_times\n\n), ticket_schedules as (\n\n    select \n      *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__ticket_schedules\"\n\n), schedule as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__schedule_spine\"\n\n), first_reply_time as (\n\n    select\n      ticket_id,\n      end_user_comment_created_at,\n      agent_responded_at\n\n    from ticket_reply_times\n    where is_first_comment\n\n), ticket_first_reply_time as (\n\n  select \n    first_reply_time.ticket_id,\n    ticket_schedules.schedule_created_at,\n    ticket_schedules.schedule_invalidated_at,\n    ticket_schedules.schedule_id,\n\n    -- bringing this in the determine which schedule (Daylight Savings vs Standard time) to use\n    min(first_reply_time.agent_responded_at) as agent_responded_at,\n\n    (\n        (\n        (\n        (\n        ((cast(ticket_schedules.schedule_created_at as timestamp))::date - (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::date)\n     * 24 + date_part('hour', (cast(ticket_schedules.schedule_created_at as timestamp))::timestamp) - date_part('hour', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + date_part('minute', (cast(ticket_schedules.schedule_created_at as timestamp))::timestamp) - date_part('minute', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp))\n     * 60 + floor(date_part('second', (cast(ticket_schedules.schedule_created_at as timestamp))::timestamp)) - floor(date_part('second', (cast(-- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date)as timestamp))::timestamp)))\n     /60\n          ) as start_time_in_minutes_from_week,\n    greatest(0,\n      (\n        \n        (\n        (\n        (\n        ((least(ticket_schedules.schedule_invalidated_at, min(first_reply_time.agent_responded_at)))::date - (ticket_schedules.schedule_created_at)::date)\n     * 24 + date_part('hour', (least(ticket_schedules.schedule_invalidated_at, min(first_reply_time.agent_responded_at)))::timestamp) - date_part('hour', (ticket_schedules.schedule_created_at)::timestamp))\n     * 60 + date_part('minute', (least(ticket_schedules.schedule_invalidated_at, min(first_reply_time.agent_responded_at)))::timestamp) - date_part('minute', (ticket_schedules.schedule_created_at)::timestamp))\n     * 60 + floor(date_part('second', (least(ticket_schedules.schedule_invalidated_at, min(first_reply_time.agent_responded_at)))::timestamp)) - floor(date_part('second', (ticket_schedules.schedule_created_at)::timestamp)))\n    /60\n        )) as raw_delta_in_minutes,\n    -- Sunday as week start date\ncast(\n\n    date_trunc('week', \n\n    ticket_schedules.schedule_created_at + ((interval '1 day') * (1))\n\n) + ((interval '1 day') * (-1))\n\n as date) as start_week_date\n  \n  from first_reply_time\n  join ticket_schedules on first_reply_time.ticket_id = ticket_schedules.ticket_id\n  group by 1, 2, 3, 4\n\n), weeks as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 208\n    order by generated_number\n\n\n\n), weeks_cross_ticket_first_reply as (\n    -- because time is reported in minutes since the beginning of the week, we have to split up time spent on the ticket into calendar weeks\n    select \n\n      ticket_first_reply_time.*,\n      cast(generated_number - 1 as integer) as week_number\n\n    from ticket_first_reply_time\n    cross join weeks\n    where floor((start_time_in_minutes_from_week + raw_delta_in_minutes) / (7*24*60)) >= generated_number - 1\n\n), weekly_periods as (\n  \n    select \n      weeks_cross_ticket_first_reply.*, \n      -- for each week, at what minute do we start counting?\n      cast(greatest(0, start_time_in_minutes_from_week - week_number * (7*24*60)) as integer) as ticket_week_start_time,\n      -- for each week, at what minute do we stop counting?\n      cast(least(start_time_in_minutes_from_week + raw_delta_in_minutes - week_number * (7*24*60), (7*24*60)) as integer) as ticket_week_end_time\n    from weeks_cross_ticket_first_reply\n\n), intercepted_periods as (\n\n  select ticket_id,\n      week_number,\n      weekly_periods.schedule_id,\n      ticket_week_start_time,\n      ticket_week_end_time,\n      schedule.start_time_utc as schedule_start_time,\n      schedule.end_time_utc as schedule_end_time,\n      least(ticket_week_end_time, schedule.end_time_utc) - greatest(ticket_week_start_time, schedule.start_time_utc) as scheduled_minutes\n  from weekly_periods\n  join schedule on ticket_week_start_time <= schedule.end_time_utc \n    and ticket_week_end_time >= schedule.start_time_utc\n    and weekly_periods.schedule_id = schedule.schedule_id\n      -- this chooses the Daylight Savings Time or Standard Time version of the schedule\n      -- We have everything calculated within a week, so take us to the appropriate week first by adding the week_number * minutes-in-a-week to the minute-mark where we start and stop counting for the week\n    and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_end_time))\n\n as timestamp) > cast(schedule.valid_from as timestamp)\n    and cast( \n\n    start_week_date + ((interval '1 minute') * (week_number * (7*24*60) + ticket_week_start_time))\n\n as timestamp) < cast(schedule.valid_until as timestamp)\n      \n)\n\n  select ticket_id,\n         sum(scheduled_minutes) as first_reply_time_business_minutes\n  from intercepted_periods\n  group by 1\n), ticket_enriched as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_enriched\"\n\n), ticket_resolution_times_calendar as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_resolution_times_calendar\n\n), ticket_reply_times_calendar as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_reply_times_calendar\n\n), ticket_comments as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__comment_metrics\"\n\n), ticket_work_time_calendar as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_work_time_calendar\n\n-- business hour CTEs\n\n\n), ticket_first_resolution_time_business as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_first_resolution_time_business\n\n), ticket_full_resolution_time_business as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_full_resolution_time_business\n\n), ticket_work_time_business as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_work_time_business\n\n), ticket_first_reply_time_business as (\n\n  select *\n  from __dbt__cte__int_zendesk__ticket_first_reply_time_business\n\n\n-- end business hour CTEs\n\n), calendar_hour_metrics as (\n\nselect\n  ticket_enriched.*,\n  case when coalesce(ticket_comments.count_public_agent_comments, 0) = 0\n    then null\n    else ticket_reply_times_calendar.first_reply_time_calendar_minutes\n      end as first_reply_time_calendar_minutes,\n  case when coalesce(ticket_comments.count_public_agent_comments, 0) = 0\n    then null\n    else ticket_reply_times_calendar.total_reply_time_calendar_minutes\n      end as total_reply_time_calendar_minutes,\n  coalesce(ticket_comments.count_agent_comments, 0) as count_agent_comments,\n  coalesce(ticket_comments.count_public_agent_comments, 0) as count_public_agent_comments,\n  coalesce(ticket_comments.count_end_user_comments, 0) as count_end_user_comments,\n  coalesce(ticket_comments.count_public_comments, 0) as count_public_comments,\n  coalesce(ticket_comments.count_internal_comments, 0) as count_internal_comments,\n  coalesce(ticket_comments.total_comments, 0) as total_comments,\n  coalesce(ticket_comments.count_ticket_handoffs, 0) as count_ticket_handoffs, -- the number of distinct internal users who commented on the ticket\n  ticket_comments.last_comment_added_at as ticket_last_comment_date,\n  ticket_resolution_times_calendar.unique_assignee_count,\n  ticket_resolution_times_calendar.assignee_stations_count,\n  ticket_resolution_times_calendar.group_stations_count,\n  ticket_resolution_times_calendar.first_assignee_id,\n  ticket_resolution_times_calendar.last_assignee_id,\n  ticket_resolution_times_calendar.first_agent_assignment_date,\n  ticket_resolution_times_calendar.last_agent_assignment_date,\n  ticket_resolution_times_calendar.first_solved_at,\n  ticket_resolution_times_calendar.last_solved_at,\n  case when ticket_enriched.status in ('solved', 'closed')\n    then ticket_resolution_times_calendar.first_assignment_to_resolution_calendar_minutes\n    else null\n      end as first_assignment_to_resolution_calendar_minutes,\n  case when ticket_enriched.status in ('solved', 'closed')\n    then ticket_resolution_times_calendar.last_assignment_to_resolution_calendar_minutes\n    else null\n      end as last_assignment_to_resolution_calendar_minutes,\n  ticket_resolution_times_calendar.ticket_unassigned_duration_calendar_minutes,\n  ticket_resolution_times_calendar.first_resolution_calendar_minutes,\n  ticket_resolution_times_calendar.final_resolution_calendar_minutes,\n  ticket_resolution_times_calendar.total_resolutions as count_resolutions,\n  ticket_resolution_times_calendar.count_reopens,\n  ticket_work_time_calendar.ticket_deleted_count,\n  ticket_work_time_calendar.total_ticket_recoveries,\n  ticket_work_time_calendar.last_status_assignment_date,\n  ticket_work_time_calendar.new_status_duration_in_calendar_minutes,\n  ticket_work_time_calendar.open_status_duration_in_calendar_minutes,\n  ticket_work_time_calendar.agent_wait_time_in_calendar_minutes,\n  ticket_work_time_calendar.requester_wait_time_in_calendar_minutes,\n  ticket_work_time_calendar.solve_time_in_calendar_minutes,\n  ticket_work_time_calendar.agent_work_time_in_calendar_minutes,\n  ticket_work_time_calendar.on_hold_time_in_calendar_minutes,\n  coalesce(ticket_comments.count_agent_replies, 0) as total_agent_replies,\n  \n  case when ticket_enriched.is_requester_active = true and ticket_enriched.requester_last_login_at is not null\n    then (\n        (\n        (\n        (\n        ((\n    current_timestamp::timestamp\n)::date - (ticket_enriched.requester_last_login_at)::date)\n     * 24 + date_part('hour', (\n    current_timestamp::timestamp\n)::timestamp) - date_part('hour', (ticket_enriched.requester_last_login_at)::timestamp))\n     * 60 + date_part('minute', (\n    current_timestamp::timestamp\n)::timestamp) - date_part('minute', (ticket_enriched.requester_last_login_at)::timestamp))\n     * 60 + floor(date_part('second', (\n    current_timestamp::timestamp\n)::timestamp)) - floor(date_part('second', (ticket_enriched.requester_last_login_at)::timestamp)))\n     /60)\n      end as requester_last_login_age_minutes,\n  case when ticket_enriched.is_assignee_active = true and ticket_enriched.assignee_last_login_at is not null\n    then (\n        (\n        (\n        (\n        ((\n    current_timestamp::timestamp\n)::date - (ticket_enriched.assignee_last_login_at)::date)\n     * 24 + date_part('hour', (\n    current_timestamp::timestamp\n)::timestamp) - date_part('hour', (ticket_enriched.assignee_last_login_at)::timestamp))\n     * 60 + date_part('minute', (\n    current_timestamp::timestamp\n)::timestamp) - date_part('minute', (ticket_enriched.assignee_last_login_at)::timestamp))\n     * 60 + floor(date_part('second', (\n    current_timestamp::timestamp\n)::timestamp)) - floor(date_part('second', (ticket_enriched.assignee_last_login_at)::timestamp)))\n     /60)\n      end as assignee_last_login_age_minutes,\n  case when lower(ticket_enriched.status) not in ('solved','closed')\n    then (\n        (\n        (\n        (\n        ((\n    current_timestamp::timestamp\n)::date - (ticket_enriched.created_at)::date)\n     * 24 + date_part('hour', (\n    current_timestamp::timestamp\n)::timestamp) - date_part('hour', (ticket_enriched.created_at)::timestamp))\n     * 60 + date_part('minute', (\n    current_timestamp::timestamp\n)::timestamp) - date_part('minute', (ticket_enriched.created_at)::timestamp))\n     * 60 + floor(date_part('second', (\n    current_timestamp::timestamp\n)::timestamp)) - floor(date_part('second', (ticket_enriched.created_at)::timestamp)))\n     /60)\n      end as unsolved_ticket_age_minutes,\n  case when lower(ticket_enriched.status) not in ('solved','closed')\n    then (\n        (\n        (\n        (\n        ((\n    current_timestamp::timestamp\n)::date - (ticket_enriched.updated_at)::date)\n     * 24 + date_part('hour', (\n    current_timestamp::timestamp\n)::timestamp) - date_part('hour', (ticket_enriched.updated_at)::timestamp))\n     * 60 + date_part('minute', (\n    current_timestamp::timestamp\n)::timestamp) - date_part('minute', (ticket_enriched.updated_at)::timestamp))\n     * 60 + floor(date_part('second', (\n    current_timestamp::timestamp\n)::timestamp)) - floor(date_part('second', (ticket_enriched.updated_at)::timestamp)))\n     /60)\n      end as unsolved_ticket_age_since_update_minutes,\n  case when lower(ticket_enriched.status) in ('solved','closed') and ticket_comments.is_one_touch_resolution \n    then true\n    else false\n      end as is_one_touch_resolution,\n  case when lower(ticket_enriched.status) in ('solved','closed') and ticket_comments.is_two_touch_resolution \n    then true\n    else false \n      end as is_two_touch_resolution,\n  case when lower(ticket_enriched.status) in ('solved','closed') and not ticket_comments.is_one_touch_resolution\n      and not ticket_comments.is_two_touch_resolution \n    then true\n    else false \n      end as is_multi_touch_resolution\n\n\nfrom ticket_enriched\n\nleft join ticket_reply_times_calendar\n  using (ticket_id)\n\nleft join ticket_resolution_times_calendar\n  using (ticket_id)\n\nleft join ticket_work_time_calendar\n  using (ticket_id)\n\nleft join ticket_comments\n  using(ticket_id)\n\n\n\n), business_hour_metrics as (\n\n  select \n    ticket_enriched.ticket_id,\n    ticket_first_resolution_time_business.first_resolution_business_minutes,\n    ticket_full_resolution_time_business.full_resolution_business_minutes,\n    ticket_first_reply_time_business.first_reply_time_business_minutes,\n    ticket_work_time_business.agent_wait_time_in_business_minutes,\n    ticket_work_time_business.requester_wait_time_in_business_minutes,\n    ticket_work_time_business.solve_time_in_business_minutes,\n    ticket_work_time_business.agent_work_time_in_business_minutes,\n    ticket_work_time_business.on_hold_time_in_business_minutes,\n    ticket_work_time_business.new_status_duration_in_business_minutes,\n    ticket_work_time_business.open_status_duration_in_business_minutes\n\n  from ticket_enriched\n\n  left join ticket_first_resolution_time_business\n    using (ticket_id)\n\n  left join ticket_full_resolution_time_business\n    using (ticket_id)\n  \n  left join ticket_first_reply_time_business\n    using (ticket_id)  \n  \n  left join ticket_work_time_business\n    using (ticket_id)\n\n)\n\nselect\n  calendar_hour_metrics.*,\n  case when calendar_hour_metrics.status in ('solved', 'closed')\n    then coalesce(business_hour_metrics.first_resolution_business_minutes,0)\n    else null\n      end as first_resolution_business_minutes,\n  case when calendar_hour_metrics.status in ('solved', 'closed')\n    then coalesce(business_hour_metrics.full_resolution_business_minutes,0)\n    else null\n      end as full_resolution_business_minutes,\n  case when coalesce(calendar_hour_metrics.count_public_agent_comments, 0) = 0\n    then null\n    else coalesce(business_hour_metrics.first_reply_time_business_minutes,0)\n      end as first_reply_time_business_minutes,\n  coalesce(business_hour_metrics.agent_wait_time_in_business_minutes,0) as agent_wait_time_in_business_minutes,\n  coalesce(business_hour_metrics.requester_wait_time_in_business_minutes,0) as requester_wait_time_in_business_minutes,\n  coalesce(business_hour_metrics.solve_time_in_business_minutes,0) as solve_time_in_business_minutes,\n  coalesce(business_hour_metrics.agent_work_time_in_business_minutes,0) as agent_work_time_in_business_minutes,\n  coalesce(business_hour_metrics.on_hold_time_in_business_minutes,0) as on_hold_time_in_business_minutes,\n  coalesce(business_hour_metrics.new_status_duration_in_business_minutes,0) as new_status_duration_in_business_minutes,\n  coalesce(business_hour_metrics.open_status_duration_in_business_minutes,0) as open_status_duration_in_business_minutes\n\nfrom calendar_hour_metrics\n\nleft join business_hour_metrics \n  using (ticket_id)\n\n", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_metrics\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:39.499803Z", "completed_at": "2023-11-15T02:15:39.511164Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.522679Z", "completed_at": "2023-11-15T02:15:39.522685Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.027479887008666992, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.zendesk__sla_policies", "compiled": true, "compiled_code": "--final step where we union together all of the reply time, agent work time, and requester wait time sla's\n\nwith reply_time_sla as (\n\n  select * \n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__reply_time_combined\"\n\n), agent_work_calendar_sla as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__agent_work_time_calendar_hours\"\n\n), requester_wait_calendar_sla as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__requester_wait_time_calendar_hours\"\n\n\n\n), agent_work_business_sla as (\n\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__agent_work_time_business_hours\"\n\n), requester_wait_business_sla as (\n  select *\n  from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__requester_wait_time_business_hours\"\n\n\n\n), all_slas_unioned as (\n  select\n    ticket_id,\n    sla_policy_name,\n    metric,\n    sla_applied_at,\n    target,\n    in_business_hours,\n    sla_breach_at,\n    sla_elapsed_time,\n    is_sla_breached\n  from reply_time_sla\n\nunion all\n\n  select\n    ticket_id,\n    sla_policy_name,\n    'agent_work_time' as metric,\n    sla_applied_at,\n    target,\n    false as in_business_hours,\n    max(sla_breach_at) as sla_breach_at,\n    max(running_total_calendar_minutes) as sla_elapsed_time,\n    \n\n    bool_or( is_breached_during_schedule )\n\n\n  from agent_work_calendar_sla\n\n  group by 1, 2, 3, 4, 5, 6\n\nunion all\n\n  select\n    ticket_id,\n    sla_policy_name,\n    'requester_wait_time' as metric,\n    sla_applied_at,\n    target,\n    false as in_business_hours,\n    max(sla_breach_at) as sla_breach_at,\n    max(running_total_calendar_minutes) as sla_elapsed_time,\n    \n\n    bool_or( is_breached_during_schedule )\n\n\n  from requester_wait_calendar_sla\n\n  group by 1, 2, 3, 4, 5, 6\n\n\n\n\nunion all \n\n  select \n    ticket_id,\n    sla_policy_name,\n    'agent_work_time' as metric,\n    sla_applied_at,\n    target,\n    true as in_business_hours,\n    max(sla_breach_at) as sla_breach_at,\n    max(running_total_scheduled_minutes) as sla_elapsed_time,\n    \n\n    bool_or( is_breached_during_schedule )\n\n\n  from agent_work_business_sla\n  \n  group by 1, 2, 3, 4, 5, 6\n\nunion all \n\n  select \n    ticket_id,\n    sla_policy_name,\n    'requester_wait_time' as metric,\n    sla_applied_at,\n    target,\n    true as in_business_hours,\n    max(sla_breach_at) as sla_breach_at,\n    max(running_total_scheduled_minutes) as sla_elapsed_time,\n    \n\n    bool_or( is_breached_during_schedule )\n\n\n    \n  from requester_wait_business_sla\n  \n  group by 1, 2, 3, 4, 5, 6\n\n\n\n)\n\nselect \n  md5(cast(coalesce(cast(ticket_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(metric as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sla_applied_at as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as sla_event_id,\n  ticket_id,\n  sla_policy_name,\n  metric,\n  sla_applied_at,\n  target,\n  in_business_hours,\n  sla_breach_at,\n  case when sla_elapsed_time is null\n    then \n        (\n        (\n        ((\n    current_timestamp::timestamp\n)::date - (sla_applied_at)::date)\n     * 24 + date_part('hour', (\n    current_timestamp::timestamp\n)::timestamp) - date_part('hour', (sla_applied_at)::timestamp))\n     * 60 + date_part('minute', (\n    current_timestamp::timestamp\n)::timestamp) - date_part('minute', (sla_applied_at)::timestamp))\n      --This will create an entry for active sla's\n    else sla_elapsed_time\n      end as sla_elapsed_time,\n  sla_breach_at > current_timestamp as is_active_sla,\n  case when (sla_breach_at > \n    current_timestamp::timestamp\n)\n    then null\n    else is_sla_breached\n      end as is_sla_breach\nfrom all_slas_unioned", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__sla_policies\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:39.524963Z", "completed_at": "2023-11-15T02:15:39.537906Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.539576Z", "completed_at": "2023-11-15T02:15:39.539583Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.019037246704101562, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.zendesk__ticket_summary", "compiled": true, "compiled_code": "with ticket_metrics as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_metrics\"\n\n), user_table as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user\"\n\n), user_sum as (\n    select\n        cast(1 as integer) as summary_helper,\n        sum(case when is_active = true\n            then 1\n            else 0\n                end) as user_count,\n        sum(case when lower(role) != 'end-user' and is_active = true\n            then 1\n            else 0\n                end) as active_agent_count,\n        sum(case when is_active = false\n            then 1\n            else 0\n                end) as deleted_user_count,\n        sum(case when lower(role) = 'end-user' and is_active = true\n            then 1\n            else 0\n                end) as end_user_count,\n        sum(case when is_suspended = true\n            then 1\n            else 0\n                end) as suspended_user_count\n    from user_table\n\n    group by 1\n\n), ticket_metric_sum as (\n    select \n        cast(1 as integer) as summary_helper,\n        sum(case when lower(status) = 'new'\n            then 1\n            else 0\n                end) as new_ticket_count,\n        sum(case when lower(status) = 'hold'\n            then 1\n            else 0\n                end) as on_hold_ticket_count,\n        sum(case when lower(status) = 'open'\n            then 1\n            else 0\n                end) as open_ticket_count,\n        sum(case when lower(status) = 'pending'\n            then 1\n            else 0\n                end) as pending_ticket_count,\n        sum(case when lower(type) = 'problem'\n            then 1\n            else 0\n                end) as problem_ticket_count,\n        sum(case when first_assignee_id != last_assignee_id\n            then 1\n            else 0\n                end) as reassigned_ticket_count,\n        sum(case when count_reopens > 0\n            then 1\n            else 0\n                end) as reopened_ticket_count,\n\n        sum(case when lower(ticket_satisfaction_score) in ('offered', 'good', 'bad')\n            then 1\n            else 0\n                end) as surveyed_satisfaction_ticket_count,\n\n        sum(case when assignee_id is null and lower(status) not in ('solved', 'closed')\n            then 1\n            else 0\n                end) as unassigned_unsolved_ticket_count,\n        sum(case when total_agent_replies < 0\n            then 1\n            else 0\n                end) as unreplied_ticket_count,\n        sum(case when total_agent_replies < 0 and lower(status) not in ('solved', 'closed')\n            then 1\n            else 0\n                end) as unreplied_unsolved_ticket_count,\n        sum(case when lower(status) not in ('solved', 'closed')\n            then 1\n            else 0\n                end) as unsolved_ticket_count,\n        sum(case when lower(status) in ('solved', 'closed')\n            then 1\n            else 0\n                end) as solved_ticket_count,\n        sum(case when lower(status) in ('deleted')\n            then 1\n            else 0\n                end) as deleted_ticket_count,\n        sum(case when total_ticket_recoveries > 0\n            then 1\n            else 0\n                end) as recovered_ticket_count,\n        sum(case when assignee_stations_count > 0\n            then 1\n            else 0\n                end) as assigned_ticket_count,\n        count(count_internal_comments) as total_internal_comments,\n        count(count_public_comments) as total_public_comments,\n        count(total_comments)\n    from ticket_metrics\n    \n    group by 1\n\n\n), final as (\n    select\n        user_sum.user_count,\n        user_sum.active_agent_count,\n        user_sum.deleted_user_count,\n        user_sum.end_user_count,\n        user_sum.suspended_user_count,\n        ticket_metric_sum.new_ticket_count,\n        ticket_metric_sum.on_hold_ticket_count,\n        ticket_metric_sum.open_ticket_count,\n        ticket_metric_sum.pending_ticket_count,\n        ticket_metric_sum.solved_ticket_count,\n        ticket_metric_sum.problem_ticket_count,\n        ticket_metric_sum.assigned_ticket_count,\n        ticket_metric_sum.reassigned_ticket_count,\n        ticket_metric_sum.reopened_ticket_count,\n        ticket_metric_sum.surveyed_satisfaction_ticket_count,\n        ticket_metric_sum.unassigned_unsolved_ticket_count,\n        ticket_metric_sum.unreplied_ticket_count,\n        ticket_metric_sum.unreplied_unsolved_ticket_count,\n        ticket_metric_sum.unsolved_ticket_count,\n        ticket_metric_sum.recovered_ticket_count,\n        ticket_metric_sum.deleted_ticket_count\n    from user_sum\n\n    left join ticket_metric_sum\n        using(summary_helper)\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_summary\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:39.530064Z", "completed_at": "2023-11-15T02:15:39.538284Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.540209Z", "completed_at": "2023-11-15T02:15:39.540211Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.019578218460083008, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk.not_null_zendesk__ticket_metrics_ticket_id.3466b76bbd", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect ticket_id\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_metrics\"\nwhere ticket_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:39.535001Z", "completed_at": "2023-11-15T02:15:39.538932Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.541293Z", "completed_at": "2023-11-15T02:15:39.541300Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.008652687072753906, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk.unique_zendesk__ticket_metrics_ticket_id.f3dc8eba5c", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    ticket_id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_metrics\"\nwhere ticket_id is not null\ngroup by ticket_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:39.544065Z", "completed_at": "2023-11-15T02:15:39.548194Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:39.548863Z", "completed_at": "2023-11-15T02:15:39.548869Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.006112813949584961, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.zendesk.unique_zendesk__sla_policies_sla_event_id.5daff4d2bd", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    sla_event_id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__sla_policies\"\nwhere sla_event_id is not null\ngroup by sla_event_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:39.512817Z", "completed_at": "2023-11-15T02:15:41.061186Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:41.061874Z", "completed_at": "2023-11-15T02:15:41.061881Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 1.5523340702056885, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__field_history_pivot", "compiled": true, "compiled_code": "-- depends_on: \"postgres\".\"zendesk_integration_tests_2\".\"ticket_field_history_data\"\n\n\n\n\n    \nwith  __dbt__cte__int_zendesk__updater_information as (\nwith users as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__user_aggregates\"\n\n), organizations as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__organization_aggregates\"\n\n), final as (\n    select\n        users.user_id as updater_user_id\n        ,users.name as updater_name\n        ,users.role as updater_role\n        ,users.email as updater_email\n        ,users.external_id as updater_external_id\n        ,users.locale as updater_locale\n        ,users.is_active as updater_is_active\n\n        --If you use user tags this will be included, if not it will be ignored.\n        \n        ,users.user_tags as updater_user_tags\n        \n\n        ,users.last_login_at as updater_last_login_at\n        ,users.time_zone as updater_time_zone\n        ,organizations.organization_id as updater_organization_id\n\n        --If you use using_domain_names tags this will be included, if not it will be ignored.\n        \n        ,organizations.domain_names as updater_organization_domain_names\n        \n\n        --If you use organization tags this will be included, if not it will be ignored.\n        \n        ,organizations.organization_tags as updater_organization_organization_tags\n        \n    from users\n\n    left join organizations\n        using(organization_id)\n)\n\nselect * \nfrom final\n),  __dbt__cte__int_zendesk__field_history_enriched as (\nwith ticket_field_history as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket_field_history\"\n\n), updater_info as (\n    select *\n    from __dbt__cte__int_zendesk__updater_information\n\n), final as (\n    select\n        ticket_field_history.*\n\n          \n\n    from ticket_field_history\n\n    left join updater_info\n        on ticket_field_history.user_id = updater_info.updater_user_id\n)\nselect *\nfrom final\n), field_history as (\n\n    select\n        ticket_id,\n        field_name,\n        valid_ending_at,\n        valid_starting_at\n\n        --Only runs if the user passes updater fields through the final ticket field history model\n        \n\n        -- doing this to figure out what values are actually null and what needs to be backfilled in zendesk__ticket_field_history\n        ,case when value is null then 'is_null' else value end as value\n\n    from __dbt__cte__int_zendesk__field_history_enriched\n    \n    where cast( date_trunc('day', valid_starting_at) as date) >= (select max(date_day) from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__field_history_pivot\")\n    \n\n), event_order as (\n\n    select \n        *,\n        row_number() over (\n            partition by cast(valid_starting_at as date), ticket_id, field_name\n            order by valid_starting_at desc\n            ) as row_num\n    from field_history\n\n), filtered as (\n\n    -- Find the last event that occurs on each day for each ticket\n\n    select *\n    from event_order\n    where row_num = 1\n\n), pivots as (\n\n    -- For each column that is in both the ticket_field_history_columns variable and the field_history table,\n    -- pivot out the value into it's own column. This will feed the daily slowly changing dimension model.\n\n    select \n        ticket_id,\n        cast(date_trunc('day', valid_starting_at) as date) as date_day\n\n        \n            \n            ,min(case when lower(field_name) = 'status' then filtered.value end) as status\n\n            --Only runs if the user passes updater fields through the final ticket field history model\n            \n        \n            \n            ,min(case when lower(field_name) = 'assignee_id' then filtered.value end) as assignee_id\n\n            --Only runs if the user passes updater fields through the final ticket field history model\n            \n        \n            \n            ,min(case when lower(field_name) = 'priority' then filtered.value end) as priority\n\n            --Only runs if the user passes updater fields through the final ticket field history model\n            \n        \n    \n    from filtered\n    group by 1,2\n\n), surrogate_key as (\n\n    select \n        *,\n        md5(cast(coalesce(cast(ticket_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date_day as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as ticket_day_id\n    from pivots\n\n)\n\nselect *\nfrom surrogate_key", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__field_history_pivot\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:41.065203Z", "completed_at": "2023-11-15T02:15:45.425646Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:45.428848Z", "completed_at": "2023-11-15T02:15:45.429181Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 4.771352052688599, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.int_zendesk__field_history_scd", "compiled": true, "compiled_code": "-- model needs to materialize as a table to avoid erroneous null values\n \n\n\n\nwith change_data as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__field_history_pivot\"\n\n), set_values as (\n\n-- each row of the pivoted table includes field values if that field was updated on that day\n-- we need to backfill to persist values that have been previously updated and are still valid \n    select \n        date_day as valid_from,\n        ticket_id,\n        ticket_day_id\n\n         \n\n        ,status\n        ,sum(case when status is null \n                then 0 \n                else 1 \n                    end) over (order by ticket_id, date_day rows unbounded preceding) as status_field_partition\n         \n\n        ,assignee_id\n        ,sum(case when assignee_id is null \n                then 0 \n                else 1 \n                    end) over (order by ticket_id, date_day rows unbounded preceding) as assignee_id_field_partition\n         \n\n        ,priority\n        ,sum(case when priority is null \n                then 0 \n                else 1 \n                    end) over (order by ticket_id, date_day rows unbounded preceding) as priority_field_partition\n        \n\n    from change_data\n\n), fill_values as (\n    select\n        valid_from, \n        ticket_id,\n        ticket_day_id\n\n         \n\n        ,first_value( status ) over (partition by status_field_partition, ticket_id order by valid_from asc rows between unbounded preceding and current row) as status\n        \n         \n\n        ,first_value( assignee_id ) over (partition by assignee_id_field_partition, ticket_id order by valid_from asc rows between unbounded preceding and current row) as assignee_id\n        \n         \n\n        ,first_value( priority ) over (partition by priority_field_partition, ticket_id order by valid_from asc rows between unbounded preceding and current row) as priority\n        \n        \n    from set_values\n) \n\nselect *\nfrom fill_values", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__field_history_scd\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:45.845385Z", "completed_at": "2023-11-15T02:15:48.144050Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:48.145828Z", "completed_at": "2023-11-15T02:15:48.145846Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 2.5722999572753906, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.zendesk__ticket_field_history", "compiled": true, "compiled_code": "with change_data as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__field_history_scd\"\n  \n    \n    where valid_from >= (select max(date_day) from \"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_field_history\")\n\n-- If no issue fields have been updated since the last incremental run, the pivoted_daily_history CTE will return no record/rows.\n-- When this is the case, we need to grab the most recent day's records from the previously built table so that we can persist \n-- those values into the future.\n\n), most_recent_data as ( \n\n    select \n        *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_field_history\"\n    where date_day = (select max(date_day) from \"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_field_history\" )\n\n\n\n), calendar as (\n\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_intermediate\".\"int_zendesk__field_calendar_spine\"\n    where date_day <= current_date\n    \n    and date_day >= (select max(date_day) from \"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_field_history\")\n    \n\n), joined as (\n\n    select \n        calendar.date_day,\n        calendar.ticket_id\n            \n             \n            , coalesce(change_data.status, most_recent_data.status) as status\n             \n            , coalesce(change_data.assignee_id, most_recent_data.assignee_id) as assignee_id\n             \n            , coalesce(change_data.priority, most_recent_data.priority) as priority\n            \n        \n        \n\n    from calendar\n    left join change_data\n        on calendar.ticket_id = change_data.ticket_id\n        and calendar.date_day = change_data.valid_from\n    \n    \n    left join most_recent_data\n        on calendar.ticket_id = most_recent_data.ticket_id\n        and calendar.date_day = most_recent_data.date_day\n    \n\n), set_values as (\n\n    select\n        date_day,\n        ticket_id\n\n        \n        , status\n        -- create a batch/partition once a new value is provided\n        , sum( case when status is null then 0 else 1 end) over ( partition by ticket_id\n            order by date_day rows unbounded preceding) as status_field_partition\n\n        \n        , assignee_id\n        -- create a batch/partition once a new value is provided\n        , sum( case when assignee_id is null then 0 else 1 end) over ( partition by ticket_id\n            order by date_day rows unbounded preceding) as assignee_id_field_partition\n\n        \n        , priority\n        -- create a batch/partition once a new value is provided\n        , sum( case when priority is null then 0 else 1 end) over ( partition by ticket_id\n            order by date_day rows unbounded preceding) as priority_field_partition\n\n        \n\n    from joined\n),\n\nfill_values as (\n\n    select  \n        date_day,\n        ticket_id\n\n        \n        -- grab the value that started this batch/partition\n        , first_value( status ) over (\n            partition by ticket_id, status_field_partition \n            order by date_day asc rows between unbounded preceding and current row) as status\n        \n        -- grab the value that started this batch/partition\n        , first_value( assignee_id ) over (\n            partition by ticket_id, assignee_id_field_partition \n            order by date_day asc rows between unbounded preceding and current row) as assignee_id\n        \n        -- grab the value that started this batch/partition\n        , first_value( priority ) over (\n            partition by ticket_id, priority_field_partition \n            order by date_day asc rows between unbounded preceding and current row) as priority\n        \n\n    from set_values\n\n), fix_null_values as (\n\n    select  \n        date_day,\n        ticket_id\n         \n\n        -- we de-nulled the true null values earlier in order to differentiate them from nulls that just needed to be backfilled\n        , case when  cast( status as TEXT ) = 'is_null' then null else status end as status\n         \n\n        -- we de-nulled the true null values earlier in order to differentiate them from nulls that just needed to be backfilled\n        , case when  cast( assignee_id as TEXT ) = 'is_null' then null else assignee_id end as assignee_id\n         \n\n        -- we de-nulled the true null values earlier in order to differentiate them from nulls that just needed to be backfilled\n        , case when  cast( priority as TEXT ) = 'is_null' then null else priority end as priority\n        \n\n    from fill_values\n\n), surrogate_key as (\n\n    select\n        md5(cast(coalesce(cast(date_day as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ticket_id as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as ticket_day_id,\n        *\n\n    from fix_null_values\n)\n\nselect *\nfrom surrogate_key", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_field_history\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2023-11-15T02:15:48.423065Z", "completed_at": "2023-11-15T02:15:48.451107Z"}, {"name": "execute", "started_at": "2023-11-15T02:15:48.451833Z", "completed_at": "2023-11-15T02:15:48.451840Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.03217577934265137, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.zendesk.zendesk__ticket_backlog", "compiled": true, "compiled_code": "--This model will only run if 'status' is included within the `ticket_field_history_columns` variable.\n\n\nwith ticket_field_history as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_field_history\"\n\n), tickets as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__ticket\"\n\n), group_names as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__group\"\n\n), users as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__user\"\n\n), brands as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__brand\"\n\n--The below model is excluded if the user does not include ticket_form_id in the variable as a low percentage of accounts use ticket forms.\n\n\n), organizations as (\n    select *\n    from \"postgres\".\"zendesk_integration_tests_2_zendesk_source\".\"stg_zendesk__organization\"\n\n), backlog as (\n    select\n        ticket_field_history.date_day\n        ,ticket_field_history.ticket_id\n        ,ticket_field_history.status\n        ,tickets.created_channel\n         --Looking at all history fields the users passed through in their dbt_project.yml file\n             --Standard ID field where the name can easily be joined from stg model.\n                ,assignee.name as assignee_name\n\n            \n         --Looking at all history fields the users passed through in their dbt_project.yml file\n             --All other fields are not ID's and can simply be included in the query.\n                ,ticket_field_history.priority\n            \n        \n\n    from ticket_field_history\n\n    left join tickets\n        on tickets.ticket_id = ticket_field_history.ticket_id\n\n    \n\n    \n\n     --Join not needed if fields is not located in variable, otherwise it is included.\n    left join users as assignee\n        on assignee.user_id = cast(ticket_field_history.assignee_id as bigint)\n    \n\n    \n\n    \n\n    \n\n    where ticket_field_history.status not in ('closed', 'solved', 'deleted')\n)\n\nselect *\nfrom backlog", "relation_name": "\"postgres\".\"zendesk_integration_tests_2_zendesk\".\"zendesk__ticket_backlog\""}], "elapsed_time": 37.28645396232605, "args": {"macro_debugging": false, "which": "generate", "log_format": "default", "use_colors": true, "print": true, "cache_selected_only": false, "select": [], "target": "postgres", "show_resource_report": false, "partial_parse": true, "quiet": false, "warn_error_options": {"include": [], "exclude": []}, "write_json": true, "log_level_file": "debug", "exclude": [], "log_format_file": "debug", "empty_catalog": false, "printer_width": 80, "favor_state": false, "indirect_selection": "eager", "introspect": true, "profiles_dir": "/Users/avinash.kunnath/.dbt", "project_dir": "/Users/avinash.kunnath/Documents/dbt_packages/zendesk/dbt_zendesk/integration_tests", "log_level": "info", "vars": {}, "send_anonymous_usage_stats": true, "partial_parse_file_diff": true, "version_check": true, "invocation_command": "dbt docs generate -t postgres", "strict_mode": false, "static_parser": true, "static": false, "compile": true, "log_path": "/Users/avinash.kunnath/Documents/dbt_packages/zendesk/dbt_zendesk/integration_tests/logs", "defer": false, "enable_legacy_logger": false, "populate_cache": true, "use_colors_file": true, "log_file_max_bytes": 10485760}}